{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4YiMLz9nqZT"
      },
      "source": [
        "# Poisoning of CICIDS-2017 dataset and detecting using LSD"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load in preprocessed and poisoned data to test LSD."
      ],
      "metadata": {
        "id": "hQpvdP9hz4Yy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyWjXBKGnzCi"
      },
      "source": [
        "## Setup and import required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clDVUdW95c8T",
        "outputId": "cd8fff09-a831-4a18-9b6d-9344b153e7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn-intelex in /usr/local/lib/python3.7/dist-packages (2021.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-intelex) (1.0.2)\n",
            "Requirement already satisfied: daal4py==2021.5.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-intelex) (2021.5.3)\n",
            "Requirement already satisfied: daal==2021.5.3 in /usr/local/lib/python3.7/dist-packages (from daal4py==2021.5.3->scikit-learn-intelex) (2021.5.3)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from daal4py==2021.5.3->scikit-learn-intelex) (1.19.5)\n",
            "Requirement already satisfied: tbb==2021.* in /usr/local/lib/python3.7/dist-packages (from daal==2021.5.3->daal4py==2021.5.3->scikit-learn-intelex) (2021.5.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install scikit-learn-intelex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7hWBpsY5e4d",
        "outputId": "52ad8153-25a6-4114-9406-86fc5d423597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ]
        }
      ],
      "source": [
        "from sklearnex import patch_sklearn\n",
        "patch_sklearn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrO59q1XCUEj"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import model_selection\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from scipy.sparse import csr_matrix, vstack, hstack\n",
        "from scipy.sparse import coo_matrix\n",
        "from keras.preprocessing.text import one_hot\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "from sklearn.semi_supervised import LabelSpreading\n",
        "#from sklearn.semi_supervised import label_propagation\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.cluster import KMeans\n",
        "import math\n",
        "#import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation , Flatten\n",
        "from sklearn.metrics import log_loss\n",
        "# from keras.optimizers import SGD\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "# from keras.layers.convolutional import UpSampling2D\n",
        "# from keras.layers.convolutional import Conv2D, MaxPooling2D, MaxPooling1D\n",
        "# from keras.layers.embeddings import Embedding\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import UpSampling2D\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, MaxPooling1D\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from scipy import sparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import PrecisionRecallDisplay\n",
        "\n",
        "#import random\n",
        "import sklearn\n",
        "from sklearn.metrics.pairwise import manhattan_distances\n",
        "from keras.models import Model\n",
        "from keras.layers import  Conv1D, multiply, GlobalMaxPool1D, Input , Lambda\n",
        "import time\n",
        "import argparse\n",
        "#import math\n",
        "from numpy import *\n",
        "import os.path as osp\n",
        "import scipy.sparse as sp\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDM9S0n4NicG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "def plot_conf_matrix(Y_val, Y_val_preds):\n",
        "    \"\"\"\n",
        "    Plots a nice looking confusion matrix using Seaborn's heatmap()\n",
        "    \"\"\"\n",
        "    sns.set(font_scale=1.5)\n",
        "    fig, ax = plt.subplots(figsize=(3,3))\n",
        "    ax = sns.heatmap(confusion_matrix(Y_val, Y_val_preds),\n",
        "                     annot=True,\n",
        "                     cbar=False,\n",
        "                     fmt='d')\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afq4T662NiXN"
      },
      "outputs": [],
      "source": [
        "def plot_conf_matrix_from_matrix(cm, title):\n",
        "    \"\"\"\n",
        "    Plots a nice looking confusion matrix using Seaborn's heatmap()\n",
        "    \"\"\"\n",
        "    sns.set(font_scale=1.5)\n",
        "    fig, ax = plt.subplots(figsize=(3,3))\n",
        "    ax = sns.heatmap(cm,\n",
        "                     annot=True,\n",
        "                     cbar=False,\n",
        "                     fmt='d')\n",
        "    plt.title(label=title)\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX_uXhNFE1C-"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KimHiQTB0uAm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# input_data = pd.read_csv('/content/drive/MyDrive/CICIDS/converted_processed_1_percent_sample.csv', index_col='Unnamed: 0')\n",
        "# input_data = pd.read_csv('/content/drive/MyDrive/CICIDS/converted_processed_5_percent_sample.csv', index_col='Unnamed: 0')\n",
        "input_data = pd.read_csv('/content/drive/MyDrive/CICIDS/Converted-Processed-CICIDS.csv', index_col='Unnamed: 0')\n",
        "\n",
        "input_tables = input_data.copy()\n",
        "input_tables.reset_index(inplace=True)\n",
        "input_tables.drop(['index'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR8UURiNPJik"
      },
      "outputs": [],
      "source": [
        "dl2 = input_tables.copy(deep=True)\n",
        "print(\"Pre-conversion values:\\n\", dl2['Label'].value_counts())\n",
        "for index, row in dl2.iterrows():\n",
        "  if row['Label'] == 'BENIGN':\n",
        "    dl2.at[index, 'Label'] = 0\n",
        "  else:\n",
        "    dl2.at[index, 'Label'] = 1\n",
        "print(\"\")\n",
        "print(\"Converted values:\\n\", dl2['Label'].value_counts())\n",
        "dl2 = dl2['Label']\n",
        "dl2 = dl2.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqNNzmKuE8_N"
      },
      "source": [
        "## Main Program Start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQhtWy4U2e2S"
      },
      "outputs": [],
      "source": [
        "###/content/drive/MyDrive/Dissertation/KNN\n",
        "### Loading\n",
        "x_train_filename = '/content/drive/MyDrive/Dissertation/KNN/X_train.sav'\n",
        "X_train = pickle.load(open(x_train_filename, 'rb'))\n",
        "x_test_filename = '/content/drive/MyDrive/Dissertation/KNN/X_test.sav'\n",
        "X_test = pickle.load(open(x_test_filename, 'rb'))\n",
        "x_val_filename = '/content/drive/MyDrive/Dissertation/KNN/X_val.sav'\n",
        "X_val = pickle.load(open(x_val_filename, 'rb'))\n",
        "y_train_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_train.sav'\n",
        "Y_train = pickle.load(open(y_train_filename, 'rb'))\n",
        "y_test_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_test.sav'\n",
        "Y_test = pickle.load(open(y_test_filename, 'rb'))\n",
        "y_val_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_val.sav'\n",
        "Y_val = pickle.load(open(y_val_filename, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGCrDblh3d3Y"
      },
      "outputs": [],
      "source": [
        "### Loading\n",
        "model_main_filename = '/content/drive/MyDrive/Dissertation/KNN/model_main.sav'\n",
        "model_main = pickle.load(open(model_main_filename, 'rb'))\n",
        "X_train_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/X_train_NoAttack.sav'\n",
        "X_train_NoAttack = pickle.load(open(X_train_NoAttack_filename, 'rb'))\n",
        "Y_train_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_train_NoAttack.sav'\n",
        "Y_train_NoAttack = pickle.load(open(Y_train_NoAttack_filename, 'rb'))\n",
        "X_val_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/X_val_NoAttack.sav'\n",
        "X_val_NoAttack = pickle.load(open(X_val_NoAttack_filename, 'rb'))\n",
        "Y_val_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_val_NoAttack.sav'\n",
        "Y_val_NoAttack = pickle.load(open(Y_val_NoAttack_filename, 'rb'))\n",
        "Y_CNN_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_CNN_NoAttack.sav'\n",
        "Y_CNN_NoAttack = pickle.load(open(Y_CNN_NoAttack_filename, 'rb'))\n",
        "Y_predict_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_predict_NoAttack.sav'\n",
        "Y_predict_NoAttack = pickle.load(open(Y_predict_NoAttack_filename, 'rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJpd6lDVoak3"
      },
      "source": [
        "Result of Model without attack on X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eymMhoRbM_Fw"
      },
      "outputs": [],
      "source": [
        "print(\"********************************Result of Model without attack******************************************************************\")\n",
        "# loss, accuracy = model_main.evaluate(X_train_NoAttack, Y_train_NoAttack, verbose=2)\n",
        "#loss, accuracy = model_main.evaluate(X_train_NoAttack, Y_train_NoAttack, verbose=2)\n",
        "loss, accuracy = model_main.evaluate(X_train_NoAttack, Y_train_NoAttack, verbose=2)\n",
        "\n",
        "print('Accuracy for Train set: %f' % (accuracy*100))\n",
        "print('Loss for Train set: %f' % (loss))\n",
        "print(\"                                                                   \")\n",
        "\n",
        "#loss, accuracy = model_main.evaluate(X_val_NoAttack, Y_val_NoAttack, verbose=2)\n",
        "loss, accuracy = model_main.evaluate(X_val_NoAttack, Y_val_NoAttack, verbose=2)\n",
        "print('Accuracy for Validation set: %f' % (accuracy*100))\n",
        "print('Loss for Train Validation set: %f' % (loss))\n",
        "print(\"                                                                   \")\n",
        "\n",
        "loss, accuracy = model_main.evaluate(X_test, Y_test, verbose=2)\n",
        "print('Accuracy for Test set: %f' % (accuracy*100))\n",
        "print('Loss for Test set:: %f' % (loss))\n",
        "print(\"                                                                   \")\n",
        "\n",
        "con_matrix = confusion_matrix(Y_test, Y_predict_NoAttack)\n",
        "print(con_matrix, \"\\n\")\n",
        "\n",
        "TN_NoAttack, FP_NoAttack, FN_NoAttack, TP_NoAttack = confusion_matrix((Y_test.astype(int).tolist()), Y_predict_NoAttack).ravel()\n",
        "print(\"TN_NoAttack:\",TN_NoAttack)\n",
        "print(\"FP_NoAttack:\",FP_NoAttack)\n",
        "print(\"FN_NoAttack:\",FN_NoAttack)\n",
        "print(\"TP_NoAttack:\",TP_NoAttack)\n",
        "print(\"                                                                   \")\n",
        "\n",
        "if (FP_NoAttack + TN_NoAttack) > 0:\n",
        "        FPR_NoAttack = FP_NoAttack/(FP_NoAttack + TN_NoAttack)\n",
        "        print(\"The FPR_NoAttack result:\", FPR_NoAttack)\n",
        "            \n",
        "if (FP_NoAttack + TN_NoAttack) > 0:\n",
        "        TPR_NoAttack=TP_NoAttack/(TP_NoAttack+FN_NoAttack)\n",
        "        print(\"The TPR_NoAttack result=\", TPR_NoAttack)\n",
        "            \n",
        "if (TN_NoAttack + FP_NoAttack) > 0:\n",
        "    TNR_NoAttack = TN_NoAttack/(TN_NoAttack + FP_NoAttack)\n",
        "    print(\"The TNR_NoAttack result:\", TNR_NoAttack)\n",
        "            \n",
        "if (FN_NoAttack + TP_NoAttack) > 0:\n",
        "    FNR_NoAttack = FN_NoAttack/(FN_NoAttack + TP_NoAttack)\n",
        "    print(\"The FNR_NoAttack result:\", FNR_NoAttack)\n",
        "            \n",
        "if ((TN_NoAttack/(TN_NoAttack + FP_NoAttack)) + (TP_NoAttack/(TP_NoAttack + FP_NoAttack))) > 0:\n",
        "    AUC_NoAttack = 1/(2*((TN_NoAttack/(TN_NoAttack + FP_NoAttack)) + (TP_NoAttack/(TP_NoAttack + FP_NoAttack))))\n",
        "    print(\"The AUC_NoAttack result:\", AUC_NoAttack)\n",
        "            \n",
        "if  (TP_NoAttack + TN_NoAttack + FP_NoAttack + FN_NoAttack) > 0:\n",
        "    ACC_NoAttack = (TP_NoAttack + TN_NoAttack)/(TP_NoAttack + TN_NoAttack + FP_NoAttack + FN_NoAttack)\n",
        "    print(\"The ACC_NoAttack result:\", ACC_NoAttack)\n",
        "            \n",
        "if  ((TP_NoAttack + FP_NoAttack) * (TP_NoAttack + FN_NoAttack) * (TN_NoAttack + FP_NoAttack) * (TN_NoAttack + FN_NoAttack)) > 0:\n",
        "    MCC_NoAttack = (TP_NoAttack * TN_NoAttack - FP_NoAttack * FN_NoAttack)/math.sqrt((TP_NoAttack + FP_NoAttack) * (TP_NoAttack + FN_NoAttack) * (TN_NoAttack + FP_NoAttack) * (TN_NoAttack + FN_NoAttack))\n",
        "    print(\"The Matthews correlation coefficient result:\", MCC_NoAttack)\n",
        "print(\"                                                                                                                               \")\n",
        "print(\"*****************************************************End of Without Attack part************************************************\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrtqHxfFnm4H"
      },
      "source": [
        "## Label Flipping Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBBHVhmcs3Ze"
      },
      "outputs": [],
      "source": [
        "print(\"*****************************************************Label Flipping Attack*****************************************************\")\n",
        "print(\"                                                                                                                               \")\n",
        "#************************** \n",
        "# Finding Malware of Train data\n",
        "malware_train = X_train.copy(deep=True)\n",
        "y_malware_train = Y_train.copy(deep=True)\n",
        "print(\"malware_train:\", malware_train.shape)\n",
        "cl_malware = list()\n",
        "z_m = 0\n",
        "count_m = 0\n",
        "drop_list = []\n",
        "for i, j in enumerate(Y_train):\n",
        "#     if j == 1:\n",
        "    if j == 0:\n",
        "        drop_list.append(X_train.index[i])\n",
        "        count_m = count_m + 1\n",
        "    else:\n",
        "        cl_malware.insert(z_m, 1)\n",
        "        z_m = z_m + 1 \n",
        "drop_list.sort(reverse=True)\n",
        "malware_train.drop(drop_list, inplace=True)\n",
        "y_malware_train.drop(drop_list, inplace=True)\n",
        "\n",
        "#***************************\n",
        "#Finding Benign of Train data\n",
        "cl_X_train = list(Y_train) \n",
        "# benign_train=sparse.lil_matrix(X_train)\n",
        "benign_train = X_train.copy(deep=True)\n",
        "y_benign_train = Y_train.copy(deep=True)\n",
        "print(\"benign_train:\", benign_train.shape)\n",
        "z_b = 0\n",
        "count_b = 0\n",
        "cl_benign = list()\n",
        "drop_list = []\n",
        "for i, j in enumerate(cl_X_train):\n",
        "#     if j == 0:\n",
        "    if j == 1:\n",
        "        drop_list.append(X_train.index[i])\n",
        "        count_b = count_b+1\n",
        "    else:\n",
        "        cl_benign.insert(z_b, 1)\n",
        "        z_b = z_b+1\n",
        "drop_list.sort(reverse=True)\n",
        "benign_train.drop(drop_list, inplace=True)\n",
        "y_benign_train.drop(drop_list, inplace=True)\n",
        "\n",
        "print(\"***********Size of Each Data Part:**********\")        \n",
        "print(\"malware_train:\", malware_train.shape)\n",
        "print(\"benign_train:\", benign_train.shape)\n",
        "#***************************************************\n",
        "row_malware_train, column_malware_train = malware_train.shape\n",
        "\n",
        "X_train_LFA = X_train.copy(deep=True)\n",
        "Y_train_LFA = Y_train.copy(deep=True)\n",
        "\n",
        "row_train_LFA, column_train_LFA = X_train_LFA.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cTH0FjZwbLC"
      },
      "outputs": [],
      "source": [
        "### Saving\n",
        "malware_train_filename = '/content/drive/MyDrive/Dissertation/KNN/malware_train.sav'\n",
        "pickle.dump(malware_train, open(malware_train_filename, 'wb'))\n",
        "y_malware_train_filename = '/content/drive/MyDrive/Dissertation/KNN/y_malware_train.sav'\n",
        "pickle.dump(y_malware_train, open(y_malware_train_filename, 'wb'))\n",
        "benign_train_filename = '/content/drive/MyDrive/Dissertation/KNN/benign_train.sav'\n",
        "pickle.dump(benign_train, open(benign_train_filename, 'wb'))\n",
        "y_benign_train_filename = '/content/drive/MyDrive/Dissertation/KNN/y_benign_train.sav'\n",
        "pickle.dump(y_benign_train, open(y_benign_train_filename, 'wb'))\n",
        "X_train_LFA_filename = '/content/drive/MyDrive/Dissertation/KNN/X_train_LFA.sav'\n",
        "pickle.dump(X_train_LFA, open(X_train_LFA_filename, 'wb'))\n",
        "Y_train_LFA_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_train_LFA.sav'\n",
        "pickle.dump(Y_train_LFA, open(Y_train_LFA_filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll8uO5Rq3AQu"
      },
      "outputs": [],
      "source": [
        "# ### Loading\n",
        "# malware_train_filename = '/content/drive/MyDrive/Dissertation/KNN/malware_train.sav'\n",
        "# malware_train = pickle.load(open(malware_train_filename, 'rb'))\n",
        "# y_malware_train_filename = '/content/drive/MyDrive/Dissertation/KNN/y_malware_train.sav'\n",
        "# y_malware_train = pickle.load(open(y_malware_train_filename, 'rb'))\n",
        "# benign_train_filename = '/content/drive/MyDrive/Dissertation/KNN/benign_train.sav'\n",
        "# benign_train = pickle.load(open(benign_train_filename, 'rb'))\n",
        "# y_benign_train_filename = '/content/drive/MyDrive/Dissertation/KNN/y_benign_train.sav'\n",
        "# y_benign_train = pickle.load(open(y_benign_train_filename, 'rb'))\n",
        "# X_train_LFA_filename = '/content/drive/MyDrive/Dissertation/KNN/X_train_LFA.sav'\n",
        "# X_train_LFA = pickle.load(open(X_train_LFA_filename, 'rb'))\n",
        "# Y_train_LFA_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_train_LFA.sav'\n",
        "# Y_train_LFA = pickle.load(open(Y_train_LFA_filename, 'rb'))\n",
        "\n",
        "# row_train_LFA, column_train_LFA = X_train_LFA.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tv2wbeRisSlW"
      },
      "outputs": [],
      "source": [
        "clusterer = KMeans(n_clusters=2, random_state=10)\n",
        "#X=X_train_LFA.toarray()\n",
        "X = X_train_LFA.copy(deep=True)\n",
        "t0 = time.time()\n",
        "cluster_labels = clusterer.fit_predict(X)\n",
        "sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
        "#print(\"sample_silhouette_values = \",sample_silhouette_values)\n",
        "t1 = time.time()\n",
        "print(\"Time for creating silhouette samples: \",t1-t0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WotJ4_5lmrKw"
      },
      "outputs": [],
      "source": [
        "### Saving silhouette_samples\n",
        "silhouette_samples_filename = '/content/drive/MyDrive/Dissertation/KNN/silhouette_samples.pkl'\n",
        "pickle.dump(sample_silhouette_values, open(silhouette_samples_filename, 'wb'))\n",
        "clusterer_filename = '/content/drive/MyDrive/Dissertation/KNN/clusterer.pkl'\n",
        "pickle.dump(clusterer, open(clusterer_filename, 'wb'))\n",
        "cluster_labels_filename = '/content/drive/MyDrive/Dissertation/KNN/cluster_labels.pkl'\n",
        "pickle.dump(cluster_labels, open(cluster_labels_filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtfE9z4CmuD4"
      },
      "outputs": [],
      "source": [
        "# ## Loading silhouette_samples\n",
        "# silhouette_samples_filename = '/content/drive/MyDrive/Dissertation/KNN/silhouette_samples.pkl'\n",
        "# sample_silhouette_values = pickle.load(open(silhouette_samples_filename, 'rb'))\n",
        "# clusterer_filename = '/content/drive/MyDrive/Dissertation/KNN/clusterer.pkl'\n",
        "# clusterer = pickle.load(open(clusterer_filename, 'rb'))\n",
        "# cluster_labels_filename = '/content/drive/MyDrive/Dissertation/KNN/cluster_labels.pkl'\n",
        "# cluster_labels = pickle.load(open(cluster_labels_filename, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iseC2daGKRWZ"
      },
      "outputs": [],
      "source": [
        "t0 = time.time()\n",
        "print(\"Values:\\n\", Y_train_LFA.value_counts())\n",
        "flipped_Y_train = list(Y_train_LFA)\n",
        "counter = 0\n",
        "\n",
        "### For CICIDS 2017 - replace silhouette_level with these values for different levels of poisoning\n",
        "### 0.05 = Original label flipping level\n",
        "### 0.15 = 5% label flipping\n",
        "### 0.29 = 10% label flipping\n",
        "### 0.335 = 15% label flipping\n",
        "### 0.36 = 20% label flipping\n",
        "### 0.405 = 25% label flipping\n",
        "\n",
        "silhouette_level = 0.405\n",
        "for new_index in range(row_train_LFA): \n",
        "    if (sample_silhouette_values[new_index]<silhouette_level):\n",
        "        flipped_Y_train[new_index] = abs(flipped_Y_train[new_index]-1)     # flipped_Y_train[new_index]=1\n",
        "        counter = counter + 1\n",
        "print(\"Benign data:\", str(flipped_Y_train.count(0)))\n",
        "print(\"Malicious data:\", str(flipped_Y_train.count(1)))\n",
        "print(\"Flipped counter:\", counter)\n",
        "\n",
        "t1 = time.time()\n",
        "print(\"Time for Label Flipping Attack: \",t1-t0)\n",
        "print(\"                                                         \") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNHBUyfKy_15"
      },
      "outputs": [],
      "source": [
        "### Saving\n",
        "flipped_Y_train_filename = '/content/drive/MyDrive/Dissertation/KNN/15/flipped_Y_train.pkl'\n",
        "pickle.dump(flipped_Y_train, open(flipped_Y_train_filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSwgdvy8zIXt"
      },
      "outputs": [],
      "source": [
        "# ## Loading\n",
        "# flipped_Y_train_filename = '/content/drive/MyDrive/Dissertation/KNN/15/flipped_Y_train.pkl'\n",
        "# flipped_Y_train = pickle.load(open(flipped_Y_train_filename, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLZN5wtl1n9S"
      },
      "outputs": [],
      "source": [
        "#**************************************************************************\n",
        "model_main_LFA_Final = Sequential()\n",
        "model_main_LFA_Final.add(Conv1D(16,2, strides=2, padding='same', input_shape=(69,1)))\n",
        "model_main_LFA_Final.add(MaxPooling1D(pool_size=(4), strides=(2)))\n",
        "model_main_LFA_Final.add(Conv1D(32,2, strides=2, padding='same', input_shape=(69,1)))\n",
        "model_main_LFA_Final.add(MaxPooling1D(pool_size=(4), strides=(2)))\n",
        "model_main_LFA_Final.add(Conv1D(64,2, strides=2, padding='same', input_shape=(69,1)))\n",
        "model_main_LFA_Final.add(Flatten())\n",
        "model_main_LFA_Final.add(Dense(1, activation='sigmoid'))\n",
        "model_main_LFA_Final.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model_main_LFA_Final.fit(X_train_LFA, np.array(flipped_Y_train), epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KttYkl4p1rQi"
      },
      "outputs": [],
      "source": [
        "Y_predict_LFA=model_main_LFA_Final.predict(X_test, verbose=0)\n",
        "Y_predict_LFA_Final=[0]*len(Y_predict_LFA)\n",
        "\n",
        "for i in range(len(Y_predict_LFA)):\n",
        "    if Y_predict_LFA[i]<0.5:\n",
        "            Y_predict_LFA[i] = 0\n",
        "    else:\n",
        "            Y_predict_LFA[i] = 1\n",
        "\n",
        "for i in range(len(Y_predict_LFA)):\n",
        "    Y_predict_LFA_Final[i] = int(Y_predict_LFA[i])  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX7PLE1Qzkke"
      },
      "outputs": [],
      "source": [
        "### Saving\n",
        "model_main_LFA_Final_filename = '/content/drive/MyDrive/Dissertation/KNN/15/model_main_LFA_Final.pkl'\n",
        "pickle.dump(model_main_LFA_Final, open(model_main_LFA_Final_filename, 'wb'))\n",
        "Y_predict_LFA_filename = '/content/drive/MyDrive/Dissertation/KNN/15/Y_predict_LFA.pkl'\n",
        "pickle.dump(Y_predict_LFA, open(Y_predict_LFA_filename, 'wb'))\n",
        "Y_predict_LFA_Final_filename = '/content/drive/MyDrive/Dissertation/KNN/15/Y_predict_LFA_Final.pkl'\n",
        "pickle.dump(Y_predict_LFA_Final, open(Y_predict_LFA_Final_filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWFtXnCU_Y8Q"
      },
      "outputs": [],
      "source": [
        "# ### Loading\n",
        "# model_main_LFA_Final_filename = '/content/drive/MyDrive/Dissertation/KNN/15/model_main_LFA_Final.pkl'\n",
        "# model_main_LFA_Final = pickle.load(open(model_main_LFA_Final_filename, 'rb'))\n",
        "# Y_predict_LFA_filename = '/content/drive/MyDrive/Dissertation/KNN/15/Y_predict_LFA.pkl'\n",
        "# Y_predict_LFA = pickle.load(open(Y_predict_LFA_filename, 'rb'))\n",
        "# Y_predict_LFA_Final_filename = '/content/drive/MyDrive/Dissertation/KNN/15/Y_predict_LFA_Final.pkl'\n",
        "# Y_predict_LFA_Final = pickle.load(open(Y_predict_LFA_Final_filename, 'rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EltzorSXDlTz"
      },
      "source": [
        "Result of Model with LFA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3j_Sep_Dn0J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb284779-e68a-49b7-c708-d6524860dad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************************Result of Model with LFA attack **************************************************************\n",
            "                                                                                                                              \n",
            "53077/53077 - 104s - loss: 0.0494 - acc: 0.9833 - 104s/epoch - 2ms/step\n",
            "Accuracy for Train set: 98.329765\n",
            "Loss for Train set: 0.049409\n",
            "                                                                   \n",
            "17693/17693 - 38s - loss: 4.9381 - acc: 0.8396 - 38s/epoch - 2ms/step\n",
            "Accuracy for Test set: 83.955640\n",
            "Loss for Test set:: 4.938063\n",
            "                                                                   \n",
            "TN_LFA: 394830\n",
            "FP_LFA: 59634\n",
            "FN_LFA: 31201\n",
            "TP_LFA: 80484\n",
            "                                                                   \n",
            "The FPR_LFA result= 0.1312183143219265\n",
            "The TPR_LFA result: 0.7206339257733805\n",
            "The TNR_LFA result: 0.8687816856780735\n",
            "The FNR_LFA result: 0.2793660742266195\n",
            "The AUC_LFA result: 0.34645634642604534\n",
            "The ACC_LFA result: 0.8395563712026339\n",
            "The Matthews correlation coefficient result: 13.885345155108466\n",
            "                                                                                                                               \n",
            "************************************************End of Label Flipping Attack part**********************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: RuntimeWarning: overflow encountered in long_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: overflow encountered in long_scalars\n"
          ]
        }
      ],
      "source": [
        "print(\"********************************Result of Model with LFA attack **************************************************************\")\n",
        "print(\"                                                                                                                              \")\n",
        "loss, accuracy = model_main_LFA_Final.evaluate(X_train_LFA, np.array(flipped_Y_train), verbose=2)\n",
        "print('Accuracy for Train set: %f' % (accuracy*100))\n",
        "print('Loss for Train set: %f' % (loss))\n",
        "print(\"                                                                   \")\n",
        "\n",
        "loss, accuracy = model_main_LFA_Final.evaluate(X_test, Y_test, verbose=2)\n",
        "print('Accuracy for Test set: %f' % (accuracy*100))\n",
        "print('Loss for Test set:: %f' % (loss))\n",
        "print(\"                                                                   \")\n",
        "\n",
        "TN_LFA, FP_LFA, FN_LFA, TP_LFA = confusion_matrix(Y_test,  Y_predict_LFA_Final).ravel()\n",
        "print(\"TN_LFA:\", TN_LFA)\n",
        "print(\"FP_LFA:\", FP_LFA)\n",
        "print(\"FN_LFA:\", FN_LFA)\n",
        "print(\"TP_LFA:\", TP_LFA)\n",
        "print(\"                                                                   \")\n",
        "\n",
        "if (FP_LFA+TN_LFA) > 0:\n",
        "        FPR_LFA=FP_LFA/(FP_LFA+TN_LFA)\n",
        "        print(\"The FPR_LFA result=\", FPR_LFA)\n",
        "            \n",
        "if (FP_LFA+TN_LFA) > 0:\n",
        "        TPR_LFA = TP_LFA/(TP_LFA+FN_LFA)\n",
        "        print(\"The TPR_LFA result:\", TPR_LFA)\n",
        "            \n",
        "if (TN_LFA+FP_LFA) > 0:\n",
        "    TNR_LFA = TN_LFA/(TN_LFA+FP_LFA)\n",
        "    print(\"The TNR_LFA result:\", TNR_LFA)\n",
        "            \n",
        "if (FN_LFA+TP_LFA) > 0:\n",
        "    FNR_LFA = FN_LFA/(FN_LFA+TP_LFA)\n",
        "    print(\"The FNR_LFA result:\", FNR_LFA)\n",
        "            \n",
        "if ((TN_LFA/(TN_LFA+FP_LFA))+(TP_LFA/(TP_LFA+FP_LFA))) > 0:\n",
        "    AUC_LFA = 1/(2*((TN_LFA/(TN_LFA+FP_LFA))+(TP_LFA/(TP_LFA+FP_LFA))))\n",
        "    print(\"The AUC_LFA result:\", AUC_LFA)\n",
        "            \n",
        "if  (TP_LFA+TN_LFA+FP_LFA+FN_LFA) > 0:\n",
        "    ACC_LFA = (TP_LFA+TN_LFA)/(TP_LFA+TN_LFA+FP_LFA+FN_LFA)\n",
        "    print(\"The ACC_LFA result:\", ACC_LFA)\n",
        "            \n",
        "if  ((TP_LFA+FP_LFA)*(TP_LFA+FN_LFA)*(TN_LFA+FP_LFA)*(TN_LFA+FN_LFA)) > 0:\n",
        "    MCC_LFA = (TP_LFA*TN_LFA-FP_LFA*FN_LFA)/math.sqrt((TP_LFA+FP_LFA)*(TP_LFA+FN_LFA)*(TN_LFA+FP_LFA)*(TN_LFA+FN_LFA))\n",
        "    print(\"The Matthews correlation coefficient result:\", MCC_LFA)\n",
        "print(\"                                                                                                                               \")\n",
        "print(\"************************************************End of Label Flipping Attack part**********************************************\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW78qlu4PvYg"
      },
      "source": [
        "Label Propagation and Label Spreading for Using in Label Based Semi-supervised Defense(LSD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wJ3gjc8NoKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4bbeb9b-14f8-4a1d-cc3e-a47c46b2e439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************************************************Label Based Semi-supervised Defense(LSD)**********************************\n",
            "                                                                                                                               \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/semi_supervised/_label_propagation.py:318: ConvergenceWarning: max_iter=30 was reached without convergence.\n",
            "  category=ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/semi_supervised/_label_propagation.py:318: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
            "  category=ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "print(\"*****************************************************Label Based Semi-supervised Defense(LSD)**********************************\")\n",
        "print(\"                                                                                                                               \")\n",
        "#***********************Label Propagation and Label Spreading for Using in Label Based Semi-supervised Defense(LSD) *******************\n",
        "X_train_LSD = X_train.copy(deep=True)\n",
        "Y_train_LSD = flipped_Y_train[:]\n",
        "\n",
        "X_val_LSD = X_val.copy()\n",
        "Y_val_LSD = Y_val.copy(deep=True)\n",
        "\n",
        "row_val_LSD,column_val_LSD = X_val_LSD.shape\n",
        "row_train_LSD,column_train_LSD = X_train_LSD.shape\n",
        "\n",
        "t4 = time.time()\n",
        "\n",
        "labels = np.full(row_train_LSD, -1)\n",
        "for i in range(row_val_LSD):\n",
        "    labels[i] = Y_val_LSD.iloc[i]\n",
        "\n",
        "X = X_train_LSD.copy(deep=True)\n",
        "label_spread = LabelSpreading(kernel='knn', alpha=0.8)\n",
        "label_propa = LabelPropagation(kernel='knn', gamma=20, n_neighbors=7, max_iter=1000, tol=0.001, n_jobs=None)\n",
        "label_spread.fit(X, labels)\n",
        "label_propa.fit(X, labels)\n",
        "output_labels_spread = label_spread.transduction_\n",
        "output_labels_propa = label_propa.transduction_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5V3RdpHU-_2"
      },
      "outputs": [],
      "source": [
        "### Saving\n",
        "X_train_LSD_filename = '/content/drive/MyDrive/Dissertation/LSD/15/X_train_LSD.pkl'\n",
        "pickle.dump(X_train_LSD, open(X_train_LSD_filename, 'wb'))\n",
        "Y_train_LSD_filename = '/content/drive/MyDrive/Dissertation/LSD/15/Y_train_LSD.pkl'\n",
        "pickle.dump(Y_train_LSD, open(Y_train_LSD_filename, 'wb'))\n",
        "X_val_LSD_filename = '/content/drive/MyDrive/Dissertation/LSD/15/X_val_LSD.pkl'\n",
        "pickle.dump(X_val_LSD, open(X_val_LSD_filename, 'wb'))\n",
        "Y_val_LSD_filename = '/content/drive/MyDrive/Dissertation/LSD/15/Y_val_LSD.pkl'\n",
        "pickle.dump(Y_val_LSD, open(Y_val_LSD_filename, 'wb'))\n",
        "output_labels_spread_filename = '/content/drive/MyDrive/Dissertation/LSD/15/output_labels_spread.pkl'\n",
        "pickle.dump(output_labels_spread, open(output_labels_spread_filename, 'wb'))\n",
        "output_labels_propa_filename = '/content/drive/MyDrive/Dissertation/LSD/15/output_labels_propa.pkl'\n",
        "pickle.dump(output_labels_propa, open(output_labels_propa_filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_Mdp6DQAERL"
      },
      "outputs": [],
      "source": [
        "# ### Loading\n",
        "# X_train_LSD_filename = '/content/drive/MyDrive/Dissertation/LSD/15/X_train_LSD.pkl'\n",
        "# X_train_LSD = pickle.load(open(X_train_LSD_filename, 'rb'))\n",
        "# Y_train_LSD_filename = '/content/drive/MyDrive/Dissertation/LSD/15/Y_train_LSD.pkl'\n",
        "# Y_train_LSD = pickle.load(open(Y_train_LSD_filename, 'rb'))\n",
        "# X_val_LSD_filename = '/content/drive/MyDrive/Dissertation/LSD/15/X_val_LSD.pkl'\n",
        "# X_val_LSD = pickle.load(open(X_val_LSD_filename, 'rb'))\n",
        "# Y_val_LSD_filename = '/content/drive/MyDrive/Dissertation/LSD/15/Y_val_LSD.pkl'\n",
        "# Y_val_LSD = pickle.load(open(Y_val_LSD_filename, 'rb'))\n",
        "# output_labels_spread_filename = '/content/drive/MyDrive/Dissertation/LSD/15/output_labels_spread.pkl'\n",
        "# output_labels_spread = pickle.load(open(output_labels_spread_filename, 'rb'))\n",
        "# output_labels_propa_filename = '/content/drive/MyDrive/Dissertation/LSD/15/output_labels_propa.pkl'\n",
        "# output_labels_propa = pickle.load(open(output_labels_propa_filename, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5Lok5X8g-cU"
      },
      "outputs": [],
      "source": [
        "#*******************Convolutional Neural Network for Using in Label Based Semi-supervised Defense(LSD) ******************************\n",
        "CNN_model_for_LSD = Sequential()\n",
        "CNN_model_for_LSD.add(Conv1D(16,2, strides=2, padding='same', input_shape=(69,1)))\n",
        "CNN_model_for_LSD.add(MaxPooling1D(pool_size=(4), strides=(2)))\n",
        "CNN_model_for_LSD.add(Conv1D(32,2, strides=2, padding='same', input_shape=(69,1)))\n",
        "CNN_model_for_LSD.add(MaxPooling1D(pool_size=(4), strides=(2)))\n",
        "CNN_model_for_LSD.add(Conv1D(64,2, strides=2, padding='same', input_shape=(69,1)))\n",
        "CNN_model_for_LSD.add(Flatten())\n",
        "CNN_model_for_LSD.add(Dense(1, activation='sigmoid'))\n",
        "CNN_model_for_LSD.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "CNN_model_for_LSD.fit(X_train_LSD, np.asarray(Y_train_LSD), epochs=200, verbose=1)\n",
        "\n",
        "Y_predict_CNN_for_LSD = CNN_model_for_LSD.predict(X_train_LSD, verbose=0)\n",
        "\n",
        "Y_predict_CNN_LSD_Final = [0]*len(Y_predict_CNN_for_LSD)\n",
        "for i in range(len(Y_predict_CNN_for_LSD)):\n",
        "    if Y_predict_CNN_for_LSD[i] < 0.5:\n",
        "            Y_predict_CNN_for_LSD[i] = 0\n",
        "    else:\n",
        "            Y_predict_CNN_for_LSD[i] = 1\n",
        "\n",
        "for i in range(len(Y_predict_CNN_for_LSD)):\n",
        "    Y_predict_CNN_LSD_Final[i]= int(Y_predict_CNN_for_LSD[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLSTiY6RV1xL"
      },
      "outputs": [],
      "source": [
        "### Saving\n",
        "CNN_model_for_LSD_filename = '/content/drive/MyDrive/Dissertation/LSD/15/CNN_model_for_LSD.pkl'\n",
        "pickle.dump(CNN_model_for_LSD, open(CNN_model_for_LSD_filename, 'wb'))\n",
        "Y_predict_CNN_for_LSD_filename = '/content/drive/MyDrive/Dissertation/LSD/15/Y_predict_CNN_for_LSD.pkl'\n",
        "pickle.dump(Y_predict_CNN_for_LSD, open(Y_predict_CNN_for_LSD_filename, 'wb'))\n",
        "Y_predict_CNN_LSD_Final_filename = '/content/drive/MyDrive/Dissertation/LSD/15/Y_predict_CNN_LSD_Final.pkl'\n",
        "pickle.dump(Y_predict_CNN_LSD_Final, open(Y_predict_CNN_LSD_Final_filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlfVKaPKASfo"
      },
      "outputs": [],
      "source": [
        "# ### Loading\n",
        "# CNN_model_for_LSD_filename = '/content/drive/MyDrive/Dissertation/LSD/15/CNN_model_for_LSD.pkl'\n",
        "# CNN_model_for_LSD = pickle.load(open(CNN_model_for_LSD_filename, 'rb'))\n",
        "# Y_predict_CNN_for_LSD_filename = '/content/drive/MyDrive/Dissertation/LSD/15/Y_predict_CNN_for_LSD.pkl'\n",
        "# Y_predict_CNN_for_LSD = pickle.load(open(Y_predict_CNN_for_LSD_filename, 'rb'))\n",
        "# Y_predict_CNN_LSD_Final_filename = '/content/drive/MyDrive/Dissertation/LSD/15/Y_predict_CNN_LSD_Final.pkl'\n",
        "# Y_predict_CNN_LSD_Final = pickle.load(open(Y_predict_CNN_LSD_Final_filename, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCCjFgwKN6HS"
      },
      "outputs": [],
      "source": [
        "#*******************************************Voting Between CNN , label Propagation and Label Spreading**************************     \n",
        "# t4 = time.time() ### Uncomment for partial run when skipping earlier step\n",
        "Y_predict_LSD_Final = [0]*len(Y_train)\n",
        "for i in range(len(Y_train)):\n",
        "    c = Y_train_LSD[i] + Y_predict_CNN_LSD_Final[i] + output_labels_propa[i] + output_labels_spread[i]\n",
        "    if 2 <= c:\n",
        "        Y_predict_LSD_Final[i] = 1\n",
        "    else:\n",
        "        Y_predict_LSD_Final[i] = 0\n",
        "t5 = time.time()\n",
        "print(\"Time for Label Based Semi-supervised Defense =\",t5-t4)\n",
        "print(\"                                                                                                                               \")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Saving\n",
        "Y_predict_LSD_Final_filename = '/content/drive/MyDrive/Dissertation/LSD/15/Y_predict_LSD_Final.pkl'\n",
        "pickle.dump(Y_predict_LSD_Final, open(Y_predict_LSD_Final_filename, 'wb'))"
      ],
      "metadata": {
        "id": "Mw45cGNcz5I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ### Loading\n",
        "# Y_predict_LSD_Final_filename = '/content/drive/MyDrive/Dissertation/LSD/15/Y_predict_LSD_Final.pkl'\n",
        "# Y_predict_LSD_Final = pickle.load(open(Y_predict_LSD_Final_filename, 'rb'))"
      ],
      "metadata": {
        "id": "H613Kvfoz-yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvjjVUcrp2Tn"
      },
      "outputs": [],
      "source": [
        "#*********************************************************************************************************************************\n",
        "model_main_LSD = Sequential()\n",
        "model_main_LSD.add(Conv1D(16,2, strides=2, padding='same', input_shape=(69,1)))\n",
        "model_main_LSD.add(MaxPooling1D(pool_size = (4), strides=(2)))\n",
        "model_main_LSD.add(Conv1D(32,2, strides=2, padding='same', input_shape=(69,1)))\n",
        "model_main_LSD.add(MaxPooling1D(pool_size = (4), strides=(2)))\n",
        "model_main_LSD.add(Conv1D(64,2, strides=2, padding='same', input_shape=(69,1)))\n",
        "model_main_LSD.add(Flatten())\n",
        "model_main_LSD.add(Dense(1, activation='sigmoid'))\n",
        "model_main_LSD.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model_main_LSD.fit(X_train_LSD, np.asarray(Y_predict_LSD_Final), epochs=200, verbose=1)\n",
        "    \n",
        "Y_predict_LSD_Defense=model_main_LSD.predict(X_test, verbose=0)\n",
        "Y_predict_LSD_Defense_Final=[0]*len(Y_predict_LSD_Defense)\n",
        "\n",
        "for i in range(len(Y_predict_LSD_Defense)):\n",
        "    if Y_predict_LSD_Defense[i]<0.5:\n",
        "            Y_predict_LSD_Defense[i]=0\n",
        "    else:\n",
        "            Y_predict_LSD_Defense[i]=1\n",
        "\n",
        "for i in range(len(Y_predict_LSD_Defense)):\n",
        "    Y_predict_LSD_Defense_Final[i] = int(Y_predict_LSD_Defense[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNO9NpLaWIDT"
      },
      "outputs": [],
      "source": [
        "### Saving\n",
        "model_main_LSD_filename = '/content/drive/MyDrive/Dissertation/LSD/15/model_main_LSD.pkl'\n",
        "pickle.dump(model_main_LSD, open(model_main_LSD_filename, 'wb'))\n",
        "Y_predict_LSD_Defense_filename = '/content/drive/MyDrive/Dissertation/LSD/15/Y_predict_LSD_Defense.pkl'\n",
        "pickle.dump(Y_predict_LSD_Defense, open(Y_predict_LSD_Defense_filename, 'wb'))\n",
        "Y_predict_LSD_Defense_Final_filename = '/content/drive/MyDrive/Dissertation/LSD/15/Y_predict_LSD_Defense_Final.pkl'\n",
        "pickle.dump(Y_predict_LSD_Defense_Final, open(Y_predict_LSD_Defense_Final_filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1t8GvktqAc2x"
      },
      "outputs": [],
      "source": [
        "# ### Loading\n",
        "# model_main_LSD_filename = '/content/drive/MyDrive/Dissertation/LSD/15/model_main_LSD.pkl'\n",
        "# model_main_LSD = pickle.load(open(model_main_LSD_filename, 'rb'))\n",
        "# Y_predict_LSD_Defense_filename = '/content/drive/MyDrive/Dissertation/LSD/15/Y_predict_LSD_Defense.pkl'\n",
        "# Y_predict_LSD_Defense = pickle.load(open(Y_predict_LSD_Defense_filename, 'rb'))\n",
        "# Y_predict_LSD_Defense_Final_filename = '/content/drive/MyDrive/Dissertation/LSD/15/Y_predict_LSD_Defense_Final.pkl'\n",
        "# Y_predict_LSD_Defense_Final = pickle.load(open(Y_predict_LSD_Defense_Final_filename, 'rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmKpJSASg-_X"
      },
      "source": [
        "Result of Model after Label Based Semi-supervised Defense(LSD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO8KErqQhD-H"
      },
      "outputs": [],
      "source": [
        "#**************************************Result of Model after Label Based Semi-supervised Defense(LSD)**********************************\n",
        "print(\"************************Result of Model after Label Based Semi-supervised Defense(LSD)*****************************************\")\n",
        "print(\"                                                                                                                               \")\n",
        "loss, accuracy = model_main.evaluate(X_train, np.asarray(Y_predict_LSD_Final), verbose=2)\n",
        "print('Accuracy for Train set: %f' % (accuracy*100))\n",
        "print('Loss for Train set: %f' % (loss))\n",
        "print(\"                                                                   \")\n",
        "\n",
        "loss, accuracy = model_main.evaluate(X_test, Y_test, verbose=2)\n",
        "print('Accuracy for Test set: %f' % (accuracy*100))\n",
        "print('Loss for Test set: %f' % (loss))\n",
        "print(\"                                                                   \")\n",
        "\n",
        "TN_LSD, FP_LSD, FN_LSD, TP_LSD = confusion_matrix(Y_test, Y_predict_LSD_Defense_Final).ravel()\n",
        "print(\"TN_LSD:\",TN_LSD)\n",
        "print(\"FP_LSD:\",FP_LSD)\n",
        "print(\"FN_LSD:\",FN_LSD)\n",
        "print(\"TP_LSD:\",TP_LSD)\n",
        "print(\"                                                                   \")\n",
        "\n",
        "if (FP_LSD + TN_LSD) > 0:\n",
        "        FPR_LSD = FP_LSD/(FP_LSD + TN_LSD)\n",
        "        print(\"The FPR_LSD result:\", FPR_LSD)\n",
        "            \n",
        "if (FP_LSD + TN_LSD) > 0:\n",
        "        TPR_LSD = TP_LSD/(TP_LSD + FN_LSD)\n",
        "        print(\"The TPR_LSD result:\", TPR_LSD)\n",
        "            \n",
        "if (TN_LSD+FP_LSD) > 0:\n",
        "    TNR_LSD = TN_LSD/(TN_LSD + FP_LSD)\n",
        "    print(\"The TNR_LSD result:\", TNR_LSD)\n",
        "            \n",
        "if (FN_LSD + TP_LSD) > 0:\n",
        "    FNR_LSD = FN_LSD/(FN_LSD+TP_LSD)\n",
        "    print(\"The FNR_LSD result:\", FNR_LSD)\n",
        "            \n",
        "if ((TN_LSD/(TN_LSD+FP_LSD)) + (TP_LSD/(TP_LSD+FP_LSD))) > 0:\n",
        "    AUC_LSD = 1/(2*((TN_LSD/(TN_LSD+FP_LSD)) + (TP_LSD/(TP_LSD+FP_LSD))))\n",
        "    print(\"The AUC result:\", AUC_LSD)\n",
        "            \n",
        "if  (TP_LSD + TN_LSD + FP_LSD + FN_LSD) > 0:   \n",
        "    ACC_LSD = (TP_LSD + TN_LSD)/(TP_LSD + TN_LSD + FP_LSD + FN_LSD)\n",
        "    print(\"The ACC result:\", ACC_LSD)\n",
        "            \n",
        "if  ((TP_LSD + FP_LSD) * (TP_LSD + FN_LSD) * (TN_LSD + FP_LSD) * (TN_LSD + FN_LSD)) > 0:\n",
        "    MCC_LSD = (TP_LSD * TN_LSD - FP_LSD*FN_LSD)/math.sqrt((TP_LSD + FP_LSD) * (TP_LSD + FN_LSD) * (TN_LSD+FP_LSD) * (TN_LSD+FN_LSD))\n",
        "    print(\"The Matthews correlation coefficient result:\", MCC_LSD) \n",
        "print(\"                                                                                                                               \")\n",
        "print(\"*****************************************************End of Label Based Semi-supervised Defense(LSD)***************************\")   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L64bSuNADAyq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Label-based Semi-Supervised Defence.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}