{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4YiMLz9nqZT"
      },
      "source": [
        "# Poisoning of CICIDS-2017 dataset and detecting poisoning using LFA and defending with LSD/CSD/KSSD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyWjXBKGnzCi"
      },
      "source": [
        "## Setup and import required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clDVUdW95c8T",
        "outputId": "3e53cfe5-e860-4de2-d134-ba252498c5a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn-intelex in /usr/local/lib/python3.7/dist-packages (2021.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-intelex) (1.0.2)\n",
            "Requirement already satisfied: daal4py==2021.5.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-intelex) (2021.5.3)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from daal4py==2021.5.3->scikit-learn-intelex) (1.19.5)\n",
            "Requirement already satisfied: daal==2021.5.3 in /usr/local/lib/python3.7/dist-packages (from daal4py==2021.5.3->scikit-learn-intelex) (2021.5.3)\n",
            "Requirement already satisfied: tbb==2021.* in /usr/local/lib/python3.7/dist-packages (from daal==2021.5.3->daal4py==2021.5.3->scikit-learn-intelex) (2021.5.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install scikit-learn-intelex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7hWBpsY5e4d",
        "outputId": "3a1dbe91-e46e-4da8-d72e-88ac913fc919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ]
        }
      ],
      "source": [
        "from sklearnex import patch_sklearn\n",
        "patch_sklearn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrO59q1XCUEj"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import model_selection\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from scipy.sparse import csr_matrix, vstack, hstack\n",
        "from scipy.sparse import coo_matrix\n",
        "from keras.preprocessing.text import one_hot\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "from sklearn.semi_supervised import LabelSpreading\n",
        "#from sklearn.semi_supervised import label_propagation\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.cluster import KMeans\n",
        "import math\n",
        "#import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation , Flatten\n",
        "from sklearn.metrics import log_loss\n",
        "# from keras.optimizers import SGD\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "# from keras.layers.convolutional import UpSampling2D\n",
        "# from keras.layers.convolutional import Conv2D, MaxPooling2D, MaxPooling1D\n",
        "# from keras.layers.embeddings import Embedding\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import UpSampling2D\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, MaxPooling1D\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from scipy import sparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import PrecisionRecallDisplay\n",
        "\n",
        "#import random\n",
        "import sklearn\n",
        "from sklearn.metrics.pairwise import manhattan_distances\n",
        "from keras.models import Model\n",
        "from keras.layers import  Conv1D, multiply, GlobalMaxPool1D, Input , Lambda\n",
        "import time\n",
        "import argparse\n",
        "#import math\n",
        "from numpy import *\n",
        "import os.path as osp\n",
        "import scipy.sparse as sp\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDM9S0n4NicG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "def plot_conf_matrix(Y_val, Y_val_preds):\n",
        "    \"\"\"\n",
        "    Plots a nice looking confusion matrix using Seaborn's heatmap()\n",
        "    \"\"\"\n",
        "    sns.set(font_scale=1.5)\n",
        "    fig, ax = plt.subplots(figsize=(3,3))\n",
        "    ax = sns.heatmap(confusion_matrix(Y_val, Y_val_preds),\n",
        "                     annot=True,\n",
        "                     cbar=False,\n",
        "                     fmt='d')\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afq4T662NiXN"
      },
      "outputs": [],
      "source": [
        "def plot_conf_matrix_from_matrix(cm, title):\n",
        "    \"\"\"\n",
        "    Plots a nice looking confusion matrix using Seaborn's heatmap()\n",
        "    \"\"\"\n",
        "    sns.set(font_scale=1.5)\n",
        "    fig, ax = plt.subplots(figsize=(3,3))\n",
        "    ax = sns.heatmap(cm,\n",
        "                     annot=True,\n",
        "                     cbar=False,\n",
        "                     fmt='d')\n",
        "    plt.title(label=title)\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX_uXhNFE1C-"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KimHiQTB0uAm"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# input_data = pd.read_csv('/content/drive/MyDrive/CICIDS/Converted-Processed-CICIDS.csv', index_col='Unnamed: 0')\n",
        "\n",
        "# input_tables = input_data.copy()\n",
        "# input_tables.reset_index(inplace=True)\n",
        "# input_tables.drop(['index'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR8UURiNPJik"
      },
      "outputs": [],
      "source": [
        "dl2 = input_tables.copy(deep=True)\n",
        "print(\"Pre-conversion values:\\n\", dl2['Label'].value_counts())\n",
        "for index, row in dl2.iterrows():\n",
        "  if row['Label'] == 'BENIGN':\n",
        "    dl2.at[index, 'Label'] = 0\n",
        "  else:\n",
        "    dl2.at[index, 'Label'] = 1\n",
        "print(\"\")\n",
        "print(\"Converted values:\\n\", dl2['Label'].value_counts())\n",
        "dl2 = dl2['Label']\n",
        "dl2 = dl2.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqNNzmKuE8_N"
      },
      "source": [
        "## Main Program Start"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bQmqEWnLlSM"
      },
      "source": [
        "### Scale Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byhzXZvrC5rX"
      },
      "outputs": [],
      "source": [
        "# print(\"*********Semi-Supervised Deep Learning Based Approach Against Label Flipping Attack in Intrusion Detection System*****************\")\n",
        "# print(\"                                                                                                                               \")\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "cols = data.select_dtypes(include=['float64','int64']).columns\n",
        "sc_data = scaler.fit_transform(data.select_dtypes(include=['float64','int64']))\n",
        "data = pd.DataFrame(sc_data, columns = cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-9KvBXrC6Y9"
      },
      "source": [
        "### Split data to train, test, and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byZ3P1HeC882"
      },
      "outputs": [],
      "source": [
        "seed = 10\n",
        "test_size = 0.2\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(data, dl2, test_size=test_size, random_state=seed)\n",
        "test_size = 0.25\n",
        "X_train, X_val, Y_train, Y_val= train_test_split(X_train, Y_train, test_size=test_size, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKO0XTMsa2D8"
      },
      "outputs": [],
      "source": [
        "# row_val,column_val = X_train.shape\n",
        "# print(\"row_train,column_train:\", X_train.shape)\n",
        "# print(\"                                                                   \")\n",
        "# row_val,column_val = X_val.shape\n",
        "# print(\"row_val,column_val:\", X_val.shape)\n",
        "# print(\"                                                                   \")\n",
        "# row_test,column_test = X_test.shape\n",
        "# print(\"row_test,column_test:\", X_test.shape)\n",
        "# print(\"                                                                   \")\n",
        "# print(\"********************************************************************\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMGnc8JBshPu"
      },
      "outputs": [],
      "source": [
        "## /content/drive/MyDrive/Dissertation/KNN\n",
        "### Saving\n",
        "x_train_filename = '/content/drive/MyDrive/Dissertation/KNN/X_train.sav'\n",
        "pickle.dump(X_train, open(x_train_filename, 'wb'))\n",
        "x_test_filename = '/content/drive/MyDrive/Dissertation/KNN/X_test.sav'\n",
        "pickle.dump(X_test, open(x_test_filename, 'wb'))\n",
        "x_val_filename = '/content/drive/MyDrive/Dissertation/KNN/X_val.sav'\n",
        "pickle.dump(X_val, open(x_val_filename, 'wb'))\n",
        "y_train_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_train.sav'\n",
        "pickle.dump(Y_train, open(y_train_filename, 'wb'))\n",
        "y_test_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_test.sav'\n",
        "pickle.dump(Y_test, open(y_test_filename, 'wb'))\n",
        "y_val_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_val.sav'\n",
        "pickle.dump(Y_val, open(y_val_filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQhtWy4U2e2S"
      },
      "outputs": [],
      "source": [
        "# ### /content/drive/MyDrive/Dissertation/KNN\n",
        "# ## Loading\n",
        "# x_train_filename = '/content/drive/MyDrive/Dissertation/KNN/X_train.sav'\n",
        "# X_train = pickle.load(open(x_train_filename, 'rb'))\n",
        "# x_test_filename = '/content/drive/MyDrive/Dissertation/KNN/X_test.sav'\n",
        "# X_test = pickle.load(open(x_test_filename, 'rb'))\n",
        "# x_val_filename = '/content/drive/MyDrive/Dissertation/KNN/X_val.sav'\n",
        "# X_val = pickle.load(open(x_val_filename, 'rb'))\n",
        "# y_train_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_train.sav'\n",
        "# Y_train = pickle.load(open(y_train_filename, 'rb'))\n",
        "# y_test_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_test.sav'\n",
        "# Y_test = pickle.load(open(y_test_filename, 'rb'))\n",
        "# y_val_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_val.sav'\n",
        "# Y_val = pickle.load(open(y_val_filename, 'rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N5DGERvDC0o"
      },
      "source": [
        "### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzPspyVB9Jgu"
      },
      "outputs": [],
      "source": [
        "X_train_NoAttack = X_train.copy()\n",
        "# Y_train_NoAttack=Y_train[:]\n",
        "Y_train_NoAttack = Y_train.copy()\n",
        "\n",
        "X_val_NoAttack = X_val.copy()\n",
        "# Y_val_NoAttack=Y_val[:]\n",
        "Y_val_NoAttack = Y_val.copy()\n",
        "\n",
        "row_train_NoAttack, column_train_NoAttack = X_train_NoAttack.shape\n",
        "model_main = Sequential()\n",
        "# model_main.add(Embedding(row_train_NoAttack, 8, input_length=column_train_NoAttack))\n",
        "model_main.add(Conv1D(16,2, strides=2, padding='same', input_shape=(69, 1)))\n",
        "model_main.add(MaxPooling1D(pool_size=(4), strides=(2)))\n",
        "model_main.add(Conv1D(32,2, strides=2, padding='same', input_shape=(69, 1)))\n",
        "model_main.add(MaxPooling1D(pool_size=(4), strides=(2)))\n",
        "model_main.add(Conv1D(64,2, strides=2, padding='same', input_shape=(69, 1)))\n",
        "model_main.add(Flatten())\n",
        "model_main.add(Dense(1, activation='sigmoid'))\n",
        "model_main.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model_main.fit(X_train_NoAttack, Y_train_NoAttack, epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJeeYUgQPxwB"
      },
      "outputs": [],
      "source": [
        "Y_CNN_NoAttack = model_main.predict(X_test, verbose=0)\n",
        "Y_predict_NoAttack = [0]*len(Y_CNN_NoAttack)\n",
        "\n",
        "for i in range(len(Y_CNN_NoAttack)):\n",
        "    if Y_CNN_NoAttack[i] < 0.5:\n",
        "            Y_CNN_NoAttack[i] = 0\n",
        "    else:\n",
        "            Y_CNN_NoAttack[i] = 1\n",
        "\n",
        "for i in range(len(Y_CNN_NoAttack)):\n",
        "    Y_predict_NoAttack[i] = int(Y_CNN_NoAttack[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_sm7sxpuAIY"
      },
      "outputs": [],
      "source": [
        "### Saving\n",
        "model_main_filename = '/content/drive/MyDrive/Dissertation/KNN/model_main.sav'\n",
        "pickle.dump(model_main, open(model_main_filename, 'wb'))\n",
        "X_train_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/X_train_NoAttack.sav'\n",
        "pickle.dump(X_train_NoAttack, open(X_train_NoAttack_filename, 'wb'))\n",
        "Y_train_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_train_NoAttack.sav'\n",
        "pickle.dump(Y_train_NoAttack, open(Y_train_NoAttack_filename, 'wb'))\n",
        "X_val_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/X_val_NoAttack.sav'\n",
        "pickle.dump(X_val_NoAttack, open(X_val_NoAttack_filename, 'wb'))\n",
        "Y_val_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_val_NoAttack.sav'\n",
        "pickle.dump(Y_val_NoAttack, open(Y_val_NoAttack_filename, 'wb'))\n",
        "Y_CNN_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_CNN_NoAttack.sav'\n",
        "pickle.dump(Y_CNN_NoAttack, open(Y_CNN_NoAttack_filename, 'wb'))\n",
        "Y_predict_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_predict_NoAttack.sav'\n",
        "pickle.dump(Y_predict_NoAttack, open(Y_predict_NoAttack_filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGCrDblh3d3Y"
      },
      "outputs": [],
      "source": [
        "# ### Loading\n",
        "# model_main_filename = '/content/drive/MyDrive/Dissertation/KNN/model_main.sav'\n",
        "# model_main = pickle.load(open(model_main_filename, 'rb'))\n",
        "# X_train_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/X_train_NoAttack.sav'\n",
        "# X_train_NoAttack = pickle.load(open(X_train_NoAttack_filename, 'rb'))\n",
        "# Y_train_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_train_NoAttack.sav'\n",
        "# Y_train_NoAttack = pickle.load(open(Y_train_NoAttack_filename, 'rb'))\n",
        "# X_val_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/X_val_NoAttack.sav'\n",
        "# X_val_NoAttack = pickle.load(open(X_val_NoAttack_filename, 'rb'))\n",
        "# Y_val_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_val_NoAttack.sav'\n",
        "# Y_val_NoAttack = pickle.load(open(Y_val_NoAttack_filename, 'rb'))\n",
        "# Y_CNN_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_CNN_NoAttack.sav'\n",
        "# Y_CNN_NoAttack = pickle.load(open(Y_CNN_NoAttack_filename, 'rb'))\n",
        "# Y_predict_NoAttack_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_predict_NoAttack.sav'\n",
        "# Y_predict_NoAttack = pickle.load(open(Y_predict_NoAttack_filename, 'rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJpd6lDVoak3"
      },
      "source": [
        "### Result of Model without attack on X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMmEjCMbf9eK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "con_matrix = confusion_matrix(testing, Y_predict_NoAttack)\n",
        "print(con_matrix)\n",
        "TN_NoAttack, FP_NoAttack, FN_NoAttack, TP_NoAttack = confusion_matrix((Y_test.astype(int).tolist()), (Y_predict_NoAttack)).ravel()\n",
        "print(\"TN_NoAttack=\",TN_NoAttack)\n",
        "print(\"FP_NoAttack=\",FP_NoAttack)\n",
        "print(\"FN_NoAttack=\",FN_NoAttack)\n",
        "print(\"TP_NoAttack=\",TP_NoAttack)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eymMhoRbM_Fw",
        "outputId": "7f05fbef-e672-48fe-ba06-46b71e3c12fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************************Result of Model without attack******************************************************************\n",
            "53077/53077 - 92s - loss: 0.0226 - acc: 0.9931 - 92s/epoch - 2ms/step\n",
            "Accuracy for Train set: 99.313551\n",
            "Loss for Train set: 0.022632\n",
            "                                                                   \n",
            "17693/17693 - 31s - loss: 0.0231 - acc: 0.9928 - 31s/epoch - 2ms/step\n",
            "Accuracy for Validation set: 99.283755\n",
            "Loss for Train Validation set: 0.023121\n",
            "                                                                   \n",
            "17693/17693 - 31s - loss: 0.0260 - acc: 0.9929 - 31s/epoch - 2ms/step\n",
            "Accuracy for Test set: 99.287289\n",
            "Loss for Test set:: 0.025963\n",
            "                                                                   \n",
            "[[452810   1654]\n",
            " [  2381 109304]] \n",
            "\n",
            "TN_NoAttack: 452810\n",
            "FP_NoAttack: 1654\n",
            "FN_NoAttack: 2381\n",
            "TP_NoAttack: 109304\n",
            "                                                                   \n",
            "The FPR_NoAttack result: 0.003639452189832418\n",
            "The TPR_NoAttack result= 0.9786811120562295\n",
            "The TNR_NoAttack result: 0.9963605478101676\n",
            "The FNR_NoAttack result: 0.021318887943770425\n",
            "The AUC_NoAttack result: 0.2523399475009115\n",
            "The ACC_NoAttack result: 0.9928729009501033\n",
            "                                                                                                                               \n",
            "*****************************************************End of Without Attack part************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: RuntimeWarning: overflow encountered in long_scalars\n"
          ]
        }
      ],
      "source": [
        "print(\"********************************Result of Model without attack******************************************************************\")\n",
        "# loss, accuracy = model_main.evaluate(X_train_NoAttack, Y_train_NoAttack, verbose=2)\n",
        "#loss, accuracy = model_main.evaluate(X_train_NoAttack, Y_train_NoAttack, verbose=2)\n",
        "loss, accuracy = model_main.evaluate(X_train_NoAttack, Y_train_NoAttack, verbose=2)\n",
        "\n",
        "print('Accuracy for Train set: %f' % (accuracy*100))\n",
        "print('Loss for Train set: %f' % (loss))\n",
        "print(\"                                                                   \")\n",
        "\n",
        "#loss, accuracy = model_main.evaluate(X_val_NoAttack, Y_val_NoAttack, verbose=2)\n",
        "loss, accuracy = model_main.evaluate(X_val_NoAttack, Y_val_NoAttack, verbose=2)\n",
        "print('Accuracy for Validation set: %f' % (accuracy*100))\n",
        "print('Loss for Train Validation set: %f' % (loss))\n",
        "print(\"                                                                   \")\n",
        "\n",
        "loss, accuracy = model_main.evaluate(X_test, Y_test, verbose=2)\n",
        "print('Accuracy for Test set: %f' % (accuracy*100))\n",
        "print('Loss for Test set: %f' % (loss))\n",
        "print(\"                                                                   \")\n",
        "\n",
        "con_matrix = confusion_matrix(Y_test, Y_predict_NoAttack)\n",
        "print(con_matrix, \"\\n\")\n",
        "\n",
        "TN_NoAttack, FP_NoAttack, FN_NoAttack, TP_NoAttack = confusion_matrix((Y_test.astype(int).tolist()), Y_predict_NoAttack).ravel()\n",
        "print(\"TN_NoAttack:\",TN_NoAttack)\n",
        "print(\"FP_NoAttack:\",FP_NoAttack)\n",
        "print(\"FN_NoAttack:\",FN_NoAttack)\n",
        "print(\"TP_NoAttack:\",TP_NoAttack)\n",
        "print(\"                                                                   \")\n",
        "\n",
        "if (FP_NoAttack + TN_NoAttack) > 0:\n",
        "        FPR_NoAttack = FP_NoAttack/(FP_NoAttack + TN_NoAttack)\n",
        "        print(\"The FPR_NoAttack result:\", FPR_NoAttack)\n",
        "            \n",
        "if (FP_NoAttack + TN_NoAttack) > 0:\n",
        "        TPR_NoAttack=TP_NoAttack/(TP_NoAttack+FN_NoAttack)\n",
        "        print(\"The TPR_NoAttack result=\", TPR_NoAttack)\n",
        "            \n",
        "if (TN_NoAttack + FP_NoAttack) > 0:\n",
        "    TNR_NoAttack = TN_NoAttack/(TN_NoAttack + FP_NoAttack)\n",
        "    print(\"The TNR_NoAttack result:\", TNR_NoAttack)\n",
        "            \n",
        "if (FN_NoAttack + TP_NoAttack) > 0:\n",
        "    FNR_NoAttack = FN_NoAttack/(FN_NoAttack + TP_NoAttack)\n",
        "    print(\"The FNR_NoAttack result:\", FNR_NoAttack)\n",
        "            \n",
        "if ((TN_NoAttack/(TN_NoAttack + FP_NoAttack)) + (TP_NoAttack/(TP_NoAttack + FP_NoAttack))) > 0:\n",
        "    AUC_NoAttack = 1/(2*((TN_NoAttack/(TN_NoAttack + FP_NoAttack)) + (TP_NoAttack/(TP_NoAttack + FP_NoAttack))))\n",
        "    print(\"The AUC_NoAttack result:\", AUC_NoAttack)\n",
        "            \n",
        "if  (TP_NoAttack + TN_NoAttack + FP_NoAttack + FN_NoAttack) > 0:\n",
        "    ACC_NoAttack = (TP_NoAttack + TN_NoAttack)/(TP_NoAttack + TN_NoAttack + FP_NoAttack + FN_NoAttack)\n",
        "    print(\"The ACC_NoAttack result:\", ACC_NoAttack)\n",
        "            \n",
        "if  ((TP_NoAttack + FP_NoAttack) * (TP_NoAttack + FN_NoAttack) * (TN_NoAttack + FP_NoAttack) * (TN_NoAttack + FN_NoAttack)) > 0:\n",
        "    MCC_NoAttack = (TP_NoAttack * TN_NoAttack - FP_NoAttack * FN_NoAttack)/math.sqrt((TP_NoAttack + FP_NoAttack) * (TP_NoAttack + FN_NoAttack) * (TN_NoAttack + FP_NoAttack) * (TN_NoAttack + FN_NoAttack))\n",
        "    print(\"The Matthews correlation coefficient result:\", MCC_NoAttack)\n",
        "print(\"                                                                                                                               \")\n",
        "print(\"*****************************************************End of Without Attack part************************************************\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrtqHxfFnm4H"
      },
      "source": [
        "## Label Flipping Attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbocZNL6RIIF"
      },
      "source": [
        "### Splitting data into malicious and benign"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBBHVhmcs3Ze"
      },
      "outputs": [],
      "source": [
        "print(\"*****************************************************Label Flipping Attack*****************************************************\")\n",
        "print(\"                                                                                                                               \")\n",
        "#************************** \n",
        "# Finding Malware of Train data\n",
        "# malware_train= sparse.lil_matrix(X_train)\n",
        "malware_train = X_train.copy(deep=True)\n",
        "y_malware_train = Y_train.copy(deep=True)\n",
        "print(\"malware_train:\", malware_train.shape)\n",
        "cl_malware = list()\n",
        "z_m = 0\n",
        "count_m = 0\n",
        "drop_list = []\n",
        "for i, j in enumerate(Y_train):\n",
        "#     if j == 1:\n",
        "    if j == 0:\n",
        "        drop_list.append(X_train.index[i])\n",
        "        count_m = count_m + 1\n",
        "    else:\n",
        "        cl_malware.insert(z_m, 1)\n",
        "        z_m = z_m + 1 \n",
        "drop_list.sort(reverse=True)\n",
        "malware_train.drop(drop_list, inplace=True)\n",
        "y_malware_train.drop(drop_list, inplace=True)\n",
        "\n",
        "#***************************\n",
        "#Finding Benign of Train data\n",
        "cl_X_train = list(Y_train) \n",
        "# benign_train=sparse.lil_matrix(X_train)\n",
        "benign_train = X_train.copy(deep=True)\n",
        "y_benign_train = Y_train.copy(deep=True)\n",
        "print(\"benign_train:\", benign_train.shape)\n",
        "z_b = 0\n",
        "count_b = 0\n",
        "cl_benign = list()\n",
        "drop_list = []\n",
        "for i, j in enumerate(cl_X_train):\n",
        "#     if j == 0:\n",
        "    if j == 1:\n",
        "        drop_list.append(X_train.index[i])\n",
        "        count_b = count_b+1\n",
        "    else:\n",
        "        cl_benign.insert(z_b, 1)\n",
        "        z_b = z_b+1\n",
        "drop_list.sort(reverse=True)\n",
        "benign_train.drop(drop_list, inplace=True)\n",
        "y_benign_train.drop(drop_list, inplace=True)\n",
        "\n",
        "print(\"***********Size of Each Data Part:**********\")        \n",
        "print(\"malware_train:\", malware_train.shape)\n",
        "print(\"benign_train:\", benign_train.shape)\n",
        "#***************************************************\n",
        "row_malware_train, column_malware_train = malware_train.shape\n",
        "# Number_of_flipped_label=int(row_malware_train)\n",
        "\n",
        "X_train_LFA = X_train.copy(deep=True)\n",
        "# Y_train_LFA=Y_train[:]\n",
        "Y_train_LFA = Y_train.copy(deep=True)\n",
        "\n",
        "row_train_LFA, column_train_LFA = X_train_LFA.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cTH0FjZwbLC"
      },
      "outputs": [],
      "source": [
        "### Saving\n",
        "malware_train_filename = '/content/drive/MyDrive/Dissertation/KNN/malware_train.sav'\n",
        "pickle.dump(malware_train, open(malware_train_filename, 'wb'))\n",
        "y_malware_train_filename = '/content/drive/MyDrive/Dissertation/KNN/y_malware_train.sav'\n",
        "pickle.dump(y_malware_train, open(y_malware_train_filename, 'wb'))\n",
        "benign_train_filename = '/content/drive/MyDrive/Dissertation/KNN/benign_train.sav'\n",
        "pickle.dump(benign_train, open(benign_train_filename, 'wb'))\n",
        "y_benign_train_filename = '/content/drive/MyDrive/Dissertation/KNN/y_benign_train.sav'\n",
        "pickle.dump(y_benign_train, open(y_benign_train_filename, 'wb'))\n",
        "X_train_LFA_filename = '/content/drive/MyDrive/Dissertation/KNN/X_train_LFA.sav'\n",
        "pickle.dump(X_train_LFA, open(X_train_LFA_filename, 'wb'))\n",
        "Y_train_LFA_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_train_LFA.sav'\n",
        "pickle.dump(Y_train_LFA, open(Y_train_LFA_filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll8uO5Rq3AQu"
      },
      "outputs": [],
      "source": [
        "# ### loading\n",
        "# malware_train_filename = '/content/drive/MyDrive/Dissertation/KNN/malware_train.sav'\n",
        "# malware_train = pickle.load(open(malware_train_filename, 'rb'))\n",
        "# y_malware_train_filename = '/content/drive/MyDrive/Dissertation/KNN/y_malware_train.sav'\n",
        "# y_malware_train = pickle.load(open(y_malware_train_filename, 'rb'))\n",
        "# benign_train_filename = '/content/drive/MyDrive/Dissertation/KNN/benign_train.sav'\n",
        "# benign_train = pickle.load(open(benign_train_filename, 'rb'))\n",
        "# y_benign_train_filename = '/content/drive/MyDrive/Dissertation/KNN/y_benign_train.sav'\n",
        "# y_benign_train = pickle.load(open(y_benign_train_filename, 'rb'))\n",
        "# X_train_LFA_filename = '/content/drive/MyDrive/Dissertation/KNN/X_train_LFA.sav'\n",
        "# X_train_LFA = pickle.load(open(X_train_LFA_filename, 'rb'))\n",
        "# Y_train_LFA_filename = '/content/drive/MyDrive/Dissertation/KNN/Y_train_LFA.sav'\n",
        "# Y_train_LFA = pickle.load(open(Y_train_LFA_filename, 'rb'))\n",
        "\n",
        "# row_train_LFA, column_train_LFA = X_train_LFA.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4K8LsaMRDnu"
      },
      "source": [
        "### Silhouette Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tv2wbeRisSlW"
      },
      "outputs": [],
      "source": [
        "clusterer = KMeans(n_clusters=2, random_state=10)\n",
        "#X=X_train_LFA.toarray()\n",
        "X = X_train_LFA.copy(deep=True)\n",
        "t0 = time.time()\n",
        "cluster_labels = clusterer.fit_predict(X)\n",
        "sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
        "#print(\"sample_silhouette_values = \",sample_silhouette_values)\n",
        "t1 = time.time()\n",
        "print(\"Time for creating silhouette samples: \",t1-t0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WotJ4_5lmrKw"
      },
      "outputs": [],
      "source": [
        "### Saving silhouette_samples\n",
        "silhouette_samples_filename = '/content/drive/MyDrive/Dissertation/KNN/silhouette_samples.pkl'\n",
        "pickle.dump(sample_silhouette_values, open(silhouette_samples_filename, 'wb'))\n",
        "clusterer_filename = '/content/drive/MyDrive/Dissertation/KNN/clusterer.pkl'\n",
        "pickle.dump(clusterer, open(clusterer_filename, 'wb'))\n",
        "cluster_labels_filename = '/content/drive/MyDrive/Dissertation/KNN/cluster_labels.pkl'\n",
        "pickle.dump(cluster_labels, open(cluster_labels_filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtfE9z4CmuD4"
      },
      "outputs": [],
      "source": [
        "# ## Loading silhouette_samples\n",
        "# silhouette_samples_filename = '/content/drive/MyDrive/Dissertation/KNN/silhouette_samples.pkl'\n",
        "# sample_silhouette_values = pickle.load(open(silhouette_samples_filename, 'rb'))\n",
        "# clusterer_filename = '/content/drive/MyDrive/Dissertation/KNN/clusterer.pkl'\n",
        "# clusterer = pickle.load(open(clusterer_filename, 'rb'))\n",
        "# cluster_labels_filename = '/content/drive/MyDrive/Dissertation/KNN/cluster_labels.pkl'\n",
        "# cluster_labels = pickle.load(open(cluster_labels_filename, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iseC2daGKRWZ",
        "outputId": "a604c720-ba72-46a6-fe4d-94c3330bf85f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Values:\n",
            " 0    1363891\n",
            "1     334554\n",
            "dtype: int64\n",
            "Flipped counter: 76488\n",
            "Time for Label Flipping Attack:  0.6521282196044922\n",
            "                                                         \n"
          ]
        }
      ],
      "source": [
        "t0 = time.time()\n",
        "print(\"Values:\\n\", Y_train_LFA.value_counts())\n",
        "flipped_Y_train = list(Y_train_LFA)\n",
        "counter = 0\n",
        "\n",
        "### For CICIDS 2017 - replace silhouette_level with these values for different levels of poisoning\n",
        "### 0.05 = Original label flipping level\n",
        "### 0.15 = 5% label flipping\n",
        "### 0.29 = 10% label flipping\n",
        "### 0.335 = 15% label flipping\n",
        "### 0.36 = 20% label flipping\n",
        "### 0.405 = 25% label flipping\n",
        "\n",
        "silhouette_level = 0.15\n",
        "for new_index in range(row_train_LFA): \n",
        "    if (sample_silhouette_values[new_index]<silhouette_level):\n",
        "        flipped_Y_train[new_index] = abs(flipped_Y_train[new_index]-1)     # flipped_Y_train[new_index]=1\n",
        "        counter = counter + 1\n",
        "# print(flipped_Y_train.count(0))\n",
        "# print(flipped_Y_train.count(1))\n",
        "print(\"Flipped counter:\", counter)\n",
        "\n",
        "t1 = time.time()\n",
        "print(\"Time for Label Flipping Attack: \",t1-t0)\n",
        "print(\"                                                         \") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNHBUyfKy_15"
      },
      "outputs": [],
      "source": [
        "### Saving\n",
        "flipped_Y_train_filename = '/content/drive/MyDrive/Dissertation/KNN/5/flipped_Y_train.pkl'\n",
        "pickle.dump(flipped_Y_train, open(flipped_Y_train_filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSwgdvy8zIXt"
      },
      "outputs": [],
      "source": [
        "# ## Loading\n",
        "# flipped_Y_train_filename = '/content/drive/MyDrive/Dissertation/KNN/5/flipped_Y_train.pkl'\n",
        "# flipped_Y_train = pickle.load(open(flipped_Y_train_filename, 'rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUu8BmGRRRpD"
      },
      "source": [
        "### Training model with poisoned data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLZN5wtl1n9S",
        "outputId": "907961bb-8311-4ff3-b1b0-0142ebb11cdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "53077/53077 [==============================] - 202s 4ms/step - loss: 0.1536 - acc: 0.9323\n",
            "Epoch 2/200\n",
            "53077/53077 [==============================] - 200s 4ms/step - loss: 0.1189 - acc: 0.9478\n",
            "Epoch 3/200\n",
            "53077/53077 [==============================] - 196s 4ms/step - loss: 0.1122 - acc: 0.9519\n",
            "Epoch 4/200\n",
            "53077/53077 [==============================] - 195s 4ms/step - loss: 0.1081 - acc: 0.9546\n",
            "Epoch 5/200\n",
            "53077/53077 [==============================] - 197s 4ms/step - loss: 0.1049 - acc: 0.9563\n",
            "Epoch 6/200\n",
            "53077/53077 [==============================] - 200s 4ms/step - loss: 0.1024 - acc: 0.9575\n",
            "Epoch 7/200\n",
            "53077/53077 [==============================] - 200s 4ms/step - loss: 0.1002 - acc: 0.9583\n",
            "Epoch 8/200\n",
            "53077/53077 [==============================] - 203s 4ms/step - loss: 0.0979 - acc: 0.9593\n",
            "Epoch 9/200\n",
            "53077/53077 [==============================] - 204s 4ms/step - loss: 0.0954 - acc: 0.9599\n",
            "Epoch 10/200\n",
            "53077/53077 [==============================] - 197s 4ms/step - loss: 0.0928 - acc: 0.9612\n",
            "Epoch 11/200\n",
            "53077/53077 [==============================] - 195s 4ms/step - loss: 0.0913 - acc: 0.9616\n",
            "Epoch 12/200\n",
            "53077/53077 [==============================] - 196s 4ms/step - loss: 0.0900 - acc: 0.9621\n",
            "Epoch 13/200\n",
            "53077/53077 [==============================] - 196s 4ms/step - loss: 0.0891 - acc: 0.9624\n",
            "Epoch 14/200\n",
            "53077/53077 [==============================] - 196s 4ms/step - loss: 0.0885 - acc: 0.9627\n",
            "Epoch 15/200\n",
            "53077/53077 [==============================] - 195s 4ms/step - loss: 0.0876 - acc: 0.9631\n",
            "Epoch 16/200\n",
            "53077/53077 [==============================] - 196s 4ms/step - loss: 0.0867 - acc: 0.9637\n",
            "Epoch 17/200\n",
            "53077/53077 [==============================] - 197s 4ms/step - loss: 0.0862 - acc: 0.9640\n",
            "Epoch 18/200\n",
            "53077/53077 [==============================] - 189s 4ms/step - loss: 0.0854 - acc: 0.9642\n",
            "Epoch 19/200\n",
            "53077/53077 [==============================] - 187s 4ms/step - loss: 0.0848 - acc: 0.9648\n",
            "Epoch 20/200\n",
            "53077/53077 [==============================] - 188s 4ms/step - loss: 0.0842 - acc: 0.9651\n",
            "Epoch 21/200\n",
            "53077/53077 [==============================] - 193s 4ms/step - loss: 0.0837 - acc: 0.9653\n",
            "Epoch 22/200\n",
            "53077/53077 [==============================] - 197s 4ms/step - loss: 0.0833 - acc: 0.9655\n",
            "Epoch 23/200\n",
            "53077/53077 [==============================] - 199s 4ms/step - loss: 0.0829 - acc: 0.9658\n",
            "Epoch 24/200\n",
            "53077/53077 [==============================] - 192s 4ms/step - loss: 0.0824 - acc: 0.9661\n",
            "Epoch 25/200\n",
            "53077/53077 [==============================] - 189s 4ms/step - loss: 0.0822 - acc: 0.9662\n",
            "Epoch 26/200\n",
            "53077/53077 [==============================] - 190s 4ms/step - loss: 0.0817 - acc: 0.9664\n",
            "Epoch 27/200\n",
            "53077/53077 [==============================] - 186s 4ms/step - loss: 0.0812 - acc: 0.9667\n",
            "Epoch 28/200\n",
            "53077/53077 [==============================] - 186s 3ms/step - loss: 0.0810 - acc: 0.9667\n",
            "Epoch 29/200\n",
            "53077/53077 [==============================] - 184s 3ms/step - loss: 0.0807 - acc: 0.9669\n",
            "Epoch 30/200\n",
            "53077/53077 [==============================] - 186s 4ms/step - loss: 0.0805 - acc: 0.9671\n",
            "Epoch 31/200\n",
            "53077/53077 [==============================] - 188s 4ms/step - loss: 0.0803 - acc: 0.9672\n",
            "Epoch 32/200\n",
            "53077/53077 [==============================] - 188s 4ms/step - loss: 0.0799 - acc: 0.9674\n",
            "Epoch 33/200\n",
            "53077/53077 [==============================] - 187s 4ms/step - loss: 0.0796 - acc: 0.9674\n",
            "Epoch 34/200\n",
            "53077/53077 [==============================] - 188s 4ms/step - loss: 0.0795 - acc: 0.9676\n",
            "Epoch 35/200\n",
            "53077/53077 [==============================] - 184s 3ms/step - loss: 0.0791 - acc: 0.9676\n",
            "Epoch 36/200\n",
            "53077/53077 [==============================] - 183s 3ms/step - loss: 0.0789 - acc: 0.9677\n",
            "Epoch 37/200\n",
            "53077/53077 [==============================] - 183s 3ms/step - loss: 0.0787 - acc: 0.9678\n",
            "Epoch 38/200\n",
            "53077/53077 [==============================] - 183s 3ms/step - loss: 0.0784 - acc: 0.9679\n",
            "Epoch 39/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0781 - acc: 0.9680\n",
            "Epoch 40/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0779 - acc: 0.9682\n",
            "Epoch 41/200\n",
            "53077/53077 [==============================] - 180s 3ms/step - loss: 0.0777 - acc: 0.9682\n",
            "Epoch 42/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0775 - acc: 0.9684\n",
            "Epoch 43/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0774 - acc: 0.9686\n",
            "Epoch 44/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0771 - acc: 0.9688\n",
            "Epoch 45/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0770 - acc: 0.9687\n",
            "Epoch 46/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0768 - acc: 0.9688\n",
            "Epoch 47/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0765 - acc: 0.9690\n",
            "Epoch 48/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0764 - acc: 0.9690\n",
            "Epoch 49/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0762 - acc: 0.9694\n",
            "Epoch 50/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0760 - acc: 0.9694\n",
            "Epoch 51/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0760 - acc: 0.9694\n",
            "Epoch 52/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0758 - acc: 0.9696\n",
            "Epoch 53/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0758 - acc: 0.9695\n",
            "Epoch 54/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0755 - acc: 0.9697\n",
            "Epoch 55/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0754 - acc: 0.9699\n",
            "Epoch 56/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0754 - acc: 0.9699\n",
            "Epoch 57/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0751 - acc: 0.9699\n",
            "Epoch 58/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0751 - acc: 0.9699\n",
            "Epoch 59/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0750 - acc: 0.9701\n",
            "Epoch 60/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0748 - acc: 0.9703\n",
            "Epoch 61/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0747 - acc: 0.9703\n",
            "Epoch 62/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0746 - acc: 0.9704\n",
            "Epoch 63/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0746 - acc: 0.9704\n",
            "Epoch 64/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0744 - acc: 0.9704\n",
            "Epoch 65/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0743 - acc: 0.9707\n",
            "Epoch 66/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0742 - acc: 0.9706\n",
            "Epoch 67/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0741 - acc: 0.9708\n",
            "Epoch 68/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0740 - acc: 0.9708\n",
            "Epoch 69/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0740 - acc: 0.9708\n",
            "Epoch 70/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0738 - acc: 0.9709\n",
            "Epoch 71/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0738 - acc: 0.9709\n",
            "Epoch 72/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0738 - acc: 0.9709\n",
            "Epoch 73/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0737 - acc: 0.9710\n",
            "Epoch 74/200\n",
            "53077/53077 [==============================] - 178s 3ms/step - loss: 0.0735 - acc: 0.9713\n",
            "Epoch 75/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0735 - acc: 0.9711\n",
            "Epoch 76/200\n",
            "53077/53077 [==============================] - 178s 3ms/step - loss: 0.0734 - acc: 0.9712\n",
            "Epoch 77/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0734 - acc: 0.9714\n",
            "Epoch 78/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0731 - acc: 0.9713\n",
            "Epoch 79/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0731 - acc: 0.9715\n",
            "Epoch 80/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0729 - acc: 0.9715\n",
            "Epoch 81/200\n",
            "53077/53077 [==============================] - 178s 3ms/step - loss: 0.0728 - acc: 0.9717\n",
            "Epoch 82/200\n",
            "53077/53077 [==============================] - 180s 3ms/step - loss: 0.0728 - acc: 0.9716\n",
            "Epoch 83/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0727 - acc: 0.9718\n",
            "Epoch 84/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0725 - acc: 0.9719\n",
            "Epoch 85/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0725 - acc: 0.9719\n",
            "Epoch 86/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0725 - acc: 0.9719\n",
            "Epoch 87/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0723 - acc: 0.9720\n",
            "Epoch 88/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0723 - acc: 0.9722\n",
            "Epoch 89/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0722 - acc: 0.9721\n",
            "Epoch 90/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0720 - acc: 0.9723\n",
            "Epoch 91/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0720 - acc: 0.9724\n",
            "Epoch 92/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0719 - acc: 0.9726\n",
            "Epoch 93/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0718 - acc: 0.9726\n",
            "Epoch 94/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0717 - acc: 0.9724\n",
            "Epoch 95/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0716 - acc: 0.9726\n",
            "Epoch 96/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0717 - acc: 0.9726\n",
            "Epoch 97/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0716 - acc: 0.9726\n",
            "Epoch 98/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0715 - acc: 0.9729\n",
            "Epoch 99/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0714 - acc: 0.9729\n",
            "Epoch 100/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0712 - acc: 0.9729\n",
            "Epoch 101/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0713 - acc: 0.9729\n",
            "Epoch 102/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0713 - acc: 0.9730\n",
            "Epoch 103/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0711 - acc: 0.9730\n",
            "Epoch 104/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0710 - acc: 0.9732\n",
            "Epoch 105/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0710 - acc: 0.9732\n",
            "Epoch 106/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0709 - acc: 0.9732\n",
            "Epoch 107/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0709 - acc: 0.9733\n",
            "Epoch 108/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0708 - acc: 0.9734\n",
            "Epoch 109/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0707 - acc: 0.9734\n",
            "Epoch 110/200\n",
            "53077/53077 [==============================] - 178s 3ms/step - loss: 0.0706 - acc: 0.9736\n",
            "Epoch 111/200\n",
            "53077/53077 [==============================] - 189s 4ms/step - loss: 0.0706 - acc: 0.9735\n",
            "Epoch 112/200\n",
            "53077/53077 [==============================] - 187s 4ms/step - loss: 0.0705 - acc: 0.9735\n",
            "Epoch 113/200\n",
            "53077/53077 [==============================] - 185s 3ms/step - loss: 0.0703 - acc: 0.9737\n",
            "Epoch 114/200\n",
            "53077/53077 [==============================] - 181s 3ms/step - loss: 0.0704 - acc: 0.9737\n",
            "Epoch 115/200\n",
            "53077/53077 [==============================] - 180s 3ms/step - loss: 0.0704 - acc: 0.9737\n",
            "Epoch 116/200\n",
            "53077/53077 [==============================] - 180s 3ms/step - loss: 0.0703 - acc: 0.9738\n",
            "Epoch 117/200\n",
            "53077/53077 [==============================] - 181s 3ms/step - loss: 0.0703 - acc: 0.9738\n",
            "Epoch 118/200\n",
            "53077/53077 [==============================] - 179s 3ms/step - loss: 0.0701 - acc: 0.9739\n",
            "Epoch 119/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0701 - acc: 0.9739\n",
            "Epoch 120/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0700 - acc: 0.9738\n",
            "Epoch 121/200\n",
            "53077/53077 [==============================] - 180s 3ms/step - loss: 0.0700 - acc: 0.9740\n",
            "Epoch 122/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0698 - acc: 0.9741\n",
            "Epoch 123/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0699 - acc: 0.9739\n",
            "Epoch 124/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0698 - acc: 0.9741\n",
            "Epoch 125/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0698 - acc: 0.9741\n",
            "Epoch 126/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0697 - acc: 0.9741\n",
            "Epoch 127/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0696 - acc: 0.9743\n",
            "Epoch 128/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0695 - acc: 0.9743\n",
            "Epoch 129/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0694 - acc: 0.9744\n",
            "Epoch 130/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0695 - acc: 0.9744\n",
            "Epoch 131/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0694 - acc: 0.9744\n",
            "Epoch 132/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0693 - acc: 0.9746\n",
            "Epoch 133/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0692 - acc: 0.9744\n",
            "Epoch 134/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0693 - acc: 0.9745\n",
            "Epoch 135/200\n",
            "53077/53077 [==============================] - 173s 3ms/step - loss: 0.0692 - acc: 0.9746\n",
            "Epoch 136/200\n",
            "53077/53077 [==============================] - 173s 3ms/step - loss: 0.0691 - acc: 0.9748\n",
            "Epoch 137/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0691 - acc: 0.9747\n",
            "Epoch 138/200\n",
            "53077/53077 [==============================] - 180s 3ms/step - loss: 0.0691 - acc: 0.9747\n",
            "Epoch 139/200\n",
            "53077/53077 [==============================] - 178s 3ms/step - loss: 0.0690 - acc: 0.9748\n",
            "Epoch 140/200\n",
            "53077/53077 [==============================] - 178s 3ms/step - loss: 0.0690 - acc: 0.9747\n",
            "Epoch 141/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0689 - acc: 0.9748\n",
            "Epoch 142/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0689 - acc: 0.9749\n",
            "Epoch 143/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0687 - acc: 0.9750\n",
            "Epoch 144/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0688 - acc: 0.9748\n",
            "Epoch 145/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0687 - acc: 0.9750\n",
            "Epoch 146/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0686 - acc: 0.9750\n",
            "Epoch 147/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0687 - acc: 0.9750\n",
            "Epoch 148/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0686 - acc: 0.9752\n",
            "Epoch 149/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0685 - acc: 0.9752\n",
            "Epoch 150/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0684 - acc: 0.9752\n",
            "Epoch 151/200\n",
            "53077/53077 [==============================] - 181s 3ms/step - loss: 0.0685 - acc: 0.9752\n",
            "Epoch 152/200\n",
            "53077/53077 [==============================] - 182s 3ms/step - loss: 0.0683 - acc: 0.9755\n",
            "Epoch 153/200\n",
            "53077/53077 [==============================] - 181s 3ms/step - loss: 0.0682 - acc: 0.9753\n",
            "Epoch 154/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0682 - acc: 0.9754\n",
            "Epoch 155/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0681 - acc: 0.9755\n",
            "Epoch 156/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0682 - acc: 0.9755\n",
            "Epoch 157/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0680 - acc: 0.9756\n",
            "Epoch 158/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0680 - acc: 0.9756\n",
            "Epoch 159/200\n",
            "53077/53077 [==============================] - 173s 3ms/step - loss: 0.0679 - acc: 0.9757\n",
            "Epoch 160/200\n",
            "53077/53077 [==============================] - 173s 3ms/step - loss: 0.0679 - acc: 0.9757\n",
            "Epoch 161/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0679 - acc: 0.9757\n",
            "Epoch 162/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0677 - acc: 0.9759\n",
            "Epoch 163/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0677 - acc: 0.9758\n",
            "Epoch 164/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0677 - acc: 0.9758\n",
            "Epoch 165/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0676 - acc: 0.9759\n",
            "Epoch 166/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0676 - acc: 0.9759\n",
            "Epoch 167/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0675 - acc: 0.9759\n",
            "Epoch 168/200\n",
            "53077/53077 [==============================] - 173s 3ms/step - loss: 0.0675 - acc: 0.9761\n",
            "Epoch 169/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0675 - acc: 0.9760\n",
            "Epoch 170/200\n",
            "53077/53077 [==============================] - 173s 3ms/step - loss: 0.0674 - acc: 0.9760\n",
            "Epoch 171/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0673 - acc: 0.9761\n",
            "Epoch 172/200\n",
            "53077/53077 [==============================] - 173s 3ms/step - loss: 0.0673 - acc: 0.9761\n",
            "Epoch 173/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0672 - acc: 0.9762\n",
            "Epoch 174/200\n",
            "53077/53077 [==============================] - 173s 3ms/step - loss: 0.0673 - acc: 0.9761\n",
            "Epoch 175/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0671 - acc: 0.9761\n",
            "Epoch 176/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0671 - acc: 0.9763\n",
            "Epoch 177/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0671 - acc: 0.9763\n",
            "Epoch 178/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0671 - acc: 0.9762\n",
            "Epoch 179/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0669 - acc: 0.9763\n",
            "Epoch 180/200\n",
            "53077/53077 [==============================] - 173s 3ms/step - loss: 0.0669 - acc: 0.9765\n",
            "Epoch 181/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0669 - acc: 0.9764\n",
            "Epoch 182/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0667 - acc: 0.9766\n",
            "Epoch 183/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0668 - acc: 0.9765\n",
            "Epoch 184/200\n",
            "53077/53077 [==============================] - 178s 3ms/step - loss: 0.0668 - acc: 0.9765\n",
            "Epoch 185/200\n",
            "53077/53077 [==============================] - 178s 3ms/step - loss: 0.0667 - acc: 0.9765\n",
            "Epoch 186/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0665 - acc: 0.9766\n",
            "Epoch 187/200\n",
            "53077/53077 [==============================] - 183s 3ms/step - loss: 0.0665 - acc: 0.9766\n",
            "Epoch 188/200\n",
            "53077/53077 [==============================] - 177s 3ms/step - loss: 0.0666 - acc: 0.9767\n",
            "Epoch 189/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0665 - acc: 0.9766\n",
            "Epoch 190/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0664 - acc: 0.9767\n",
            "Epoch 191/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0663 - acc: 0.9768\n",
            "Epoch 192/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0665 - acc: 0.9767\n",
            "Epoch 193/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0664 - acc: 0.9768\n",
            "Epoch 194/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0663 - acc: 0.9768\n",
            "Epoch 195/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0661 - acc: 0.9769\n",
            "Epoch 196/200\n",
            "53077/53077 [==============================] - 176s 3ms/step - loss: 0.0661 - acc: 0.9769\n",
            "Epoch 197/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0662 - acc: 0.9769\n",
            "Epoch 198/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0661 - acc: 0.9770\n",
            "Epoch 199/200\n",
            "53077/53077 [==============================] - 175s 3ms/step - loss: 0.0658 - acc: 0.9771\n",
            "Epoch 200/200\n",
            "53077/53077 [==============================] - 174s 3ms/step - loss: 0.0659 - acc: 0.9770\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6f14b44550>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "#**************************************************************************\n",
        "model_main_LFA_Final = Sequential()\n",
        "#model_main_LFA_Final.add(Embedding(row_train_LFA, 8, input_length=column_train_LFA))\n",
        "model_main_LFA_Final.add(Conv1D(16,2, strides=2, padding='same', input_shape=(69,1)))\n",
        "model_main_LFA_Final.add(MaxPooling1D(pool_size=(4), strides=(2)))\n",
        "model_main_LFA_Final.add(Conv1D(32,2, strides=2, padding='same', input_shape=(69,1)))\n",
        "model_main_LFA_Final.add(MaxPooling1D(pool_size=(4), strides=(2)))\n",
        "model_main_LFA_Final.add(Conv1D(64,2, strides=2, padding='same', input_shape=(69,1)))\n",
        "model_main_LFA_Final.add(Flatten())\n",
        "model_main_LFA_Final.add(Dense(1, activation='sigmoid'))\n",
        "model_main_LFA_Final.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "#model_main_LFA_Final.fit(tf.convert_to_tensor(pd.DataFrame.sparse.from_spmatrix(X_train_LFA)), tf.convert_to_tensor(pd.DataFrame(flipped_Y_train)), epochs=200, verbose=0)\n",
        "model_main_LFA_Final.fit(X_train_LFA, np.array(flipped_Y_train), epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KttYkl4p1rQi"
      },
      "outputs": [],
      "source": [
        "Y_predict_LFA=model_main_LFA_Final.predict(X_test, verbose=0)\n",
        "Y_predict_LFA_Final=[0]*len(Y_predict_LFA)\n",
        "\n",
        "for i in range(len(Y_predict_LFA)):\n",
        "    if Y_predict_LFA[i]<0.5:\n",
        "            Y_predict_LFA[i] = 0\n",
        "    else:\n",
        "            Y_predict_LFA[i] = 1\n",
        "\n",
        "for i in range(len(Y_predict_LFA)):\n",
        "    Y_predict_LFA_Final[i] = int(Y_predict_LFA[i])  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX7PLE1Qzkke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "228ce4c7-6e2e-47f2-b4a2-d10348f77505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://b080e728-6028-41a0-8b54-3fe25563fad6/assets\n"
          ]
        }
      ],
      "source": [
        "### Saving\n",
        "model_main_LFA_Final_filename = '/content/drive/MyDrive/Dissertation/KNN/5/model_main_LFA_Final.pkl'\n",
        "pickle.dump(model_main_LFA_Final, open(model_main_LFA_Final_filename, 'wb'))\n",
        "Y_predict_LFA_filename = '/content/drive/MyDrive/Dissertation/KNN/5/Y_predict_LFA.pkl'\n",
        "pickle.dump(Y_predict_LFA, open(Y_predict_LFA_filename, 'wb'))\n",
        "Y_predict_LFA_Final_filename = '/content/drive/MyDrive/Dissertation/KNN/5/Y_predict_LFA_Final.pkl'\n",
        "pickle.dump(Y_predict_LFA_Final, open(Y_predict_LFA_Final_filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWFtXnCU_Y8Q"
      },
      "outputs": [],
      "source": [
        "# ### Loading\n",
        "# model_main_LFA_Final_filename = '/content/drive/MyDrive/Dissertation/KNN/5/model_main_LFA_Final.pkl'\n",
        "# model_main_LFA_Final = pickle.load(open(model_main_LFA_Final_filename, 'rb'))\n",
        "# Y_predict_LFA_filename = '/content/drive/MyDrive/Dissertation/KNN/5/Y_predict_LFA.pkl'\n",
        "# Y_predict_LFA = pickle.load(open(Y_predict_LFA_filename, 'rb'))\n",
        "# Y_predict_LFA_Final_filename = '/content/drive/MyDrive/Dissertation/KNN/5/Y_predict_LFA_Final.pkl'\n",
        "# Y_predict_LFA_Final = pickle.load(open(Y_predict_LFA_Final_filename, 'rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EltzorSXDlTz"
      },
      "source": [
        "### Result of Model with LFA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3j_Sep_Dn0J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9813de2e-d495-46a9-dd99-20de60c3c9a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************************Result of Model with LFA attack **************************************************************\n",
            "                                                                                                                              \n",
            "53077/53077 - 91s - loss: 0.0668 - acc: 0.9782 - 91s/epoch - 2ms/step\n",
            "Accuracy for Train set: 97.822011\n",
            "Loss for Train set: 0.066837\n",
            "                                                                   \n",
            "17693/17693 - 36s - loss: 0.4142 - acc: 0.9402 - 36s/epoch - 2ms/step\n",
            "Accuracy for Test set: 94.024718\n",
            "Loss for Test set: 0.414232\n",
            "                                                                   \n",
            "TN_LFA: 428869\n",
            "FP_LFA: 25595\n",
            "FN_LFA: 8234\n",
            "TP_LFA: 103451\n",
            "                                                                   \n",
            "The FPR_LFA result= 0.05631909238135474\n",
            "The TPR_LFA result: 0.9262747907060035\n",
            "The TNR_LFA result: 0.9436809076186453\n",
            "The FNR_LFA result: 0.07372520929399651\n",
            "The AUC_LFA result: 0.28647700522917036\n",
            "The ACC_LFA result: 0.9402471787462311\n",
            "The Matthews correlation coefficient result: 22.761575230956424\n",
            "                                                                                                                               \n",
            "************************************************End of Label Flipping Attack part**********************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: RuntimeWarning: overflow encountered in long_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: overflow encountered in long_scalars\n"
          ]
        }
      ],
      "source": [
        "print(\"********************************Result of Model with LFA attack **************************************************************\")\n",
        "print(\"                                                                                                                              \")\n",
        "loss, accuracy = model_main_LFA_Final.evaluate(X_train_LFA, np.array(flipped_Y_train), verbose=2)\n",
        "print('Accuracy for Train set: %f' % (accuracy*100))\n",
        "print('Loss for Train set: %f' % (loss))\n",
        "print(\"                                                                   \")\n",
        "\n",
        "loss, accuracy = model_main_LFA_Final.evaluate(X_test, Y_test, verbose=2)\n",
        "print('Accuracy for Test set: %f' % (accuracy*100))\n",
        "print('Loss for Test set: %f' % (loss))\n",
        "print(\"                                                                   \")\n",
        "\n",
        "TN_LFA, FP_LFA, FN_LFA, TP_LFA = confusion_matrix(Y_test,  Y_predict_LFA_Final).ravel()\n",
        "print(\"TN_LFA:\", TN_LFA)\n",
        "print(\"FP_LFA:\", FP_LFA)\n",
        "print(\"FN_LFA:\", FN_LFA)\n",
        "print(\"TP_LFA:\", TP_LFA)\n",
        "print(\"                                                                   \")\n",
        "\n",
        "if (FP_LFA+TN_LFA) > 0:\n",
        "        FPR_LFA=FP_LFA/(FP_LFA+TN_LFA)\n",
        "        print(\"The FPR_LFA result=\", FPR_LFA)\n",
        "            \n",
        "if (FP_LFA+TN_LFA) > 0:\n",
        "        TPR_LFA = TP_LFA/(TP_LFA+FN_LFA)\n",
        "        print(\"The TPR_LFA result:\", TPR_LFA)\n",
        "            \n",
        "if (TN_LFA+FP_LFA) > 0:\n",
        "    TNR_LFA = TN_LFA/(TN_LFA+FP_LFA)\n",
        "    print(\"The TNR_LFA result:\", TNR_LFA)\n",
        "            \n",
        "if (FN_LFA+TP_LFA) > 0:\n",
        "    FNR_LFA = FN_LFA/(FN_LFA+TP_LFA)\n",
        "    print(\"The FNR_LFA result:\", FNR_LFA)\n",
        "            \n",
        "if ((TN_LFA/(TN_LFA+FP_LFA))+(TP_LFA/(TP_LFA+FP_LFA))) > 0:\n",
        "    AUC_LFA = 1/(2*((TN_LFA/(TN_LFA+FP_LFA))+(TP_LFA/(TP_LFA+FP_LFA))))\n",
        "    print(\"The AUC_LFA result:\", AUC_LFA)\n",
        "            \n",
        "if  (TP_LFA+TN_LFA+FP_LFA+FN_LFA) > 0:\n",
        "    ACC_LFA = (TP_LFA+TN_LFA)/(TP_LFA+TN_LFA+FP_LFA+FN_LFA)\n",
        "    print(\"The ACC_LFA result:\", ACC_LFA)\n",
        "            \n",
        "if  ((TP_LFA+FP_LFA)*(TP_LFA+FN_LFA)*(TN_LFA+FP_LFA)*(TN_LFA+FN_LFA)) > 0:\n",
        "    MCC_LFA = (TP_LFA*TN_LFA-FP_LFA*FN_LFA)/math.sqrt((TP_LFA+FP_LFA)*(TP_LFA+FN_LFA)*(TN_LFA+FP_LFA)*(TN_LFA+FN_LFA))\n",
        "    print(\"The Matthews correlation coefficient result:\", MCC_LFA)\n",
        "print(\"                                                                                                                               \")\n",
        "print(\"************************************************End of Label Flipping Attack part**********************************************\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Silhouette Clustering Label Flipping Attack.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}